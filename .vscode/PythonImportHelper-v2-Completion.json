[
    {
        "label": "streamlit",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "streamlit",
        "description": "streamlit",
        "detail": "streamlit",
        "documentation": {}
    },
    {
        "label": "matplotlib.pyplot",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "matplotlib.pyplot",
        "description": "matplotlib.pyplot",
        "detail": "matplotlib.pyplot",
        "documentation": {}
    },
    {
        "label": "numpy",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "numpy",
        "description": "numpy",
        "detail": "numpy",
        "documentation": {}
    },
    {
        "label": "os",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "os",
        "description": "os",
        "detail": "os",
        "documentation": {}
    },
    {
        "label": "load_dotenv",
        "importPath": "dotenv",
        "description": "dotenv",
        "isExtraImport": true,
        "detail": "dotenv",
        "documentation": {}
    },
    {
        "label": "load_dotenv",
        "importPath": "dotenv",
        "description": "dotenv",
        "isExtraImport": true,
        "detail": "dotenv",
        "documentation": {}
    },
    {
        "label": "goodfire",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "goodfire",
        "description": "goodfire",
        "detail": "goodfire",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "json",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "json",
        "description": "json",
        "detail": "json",
        "documentation": {}
    },
    {
        "label": "ast",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "ast",
        "description": "ast",
        "detail": "ast",
        "documentation": {}
    },
    {
        "label": "literal_eval",
        "importPath": "ast",
        "description": "ast",
        "isExtraImport": true,
        "detail": "ast",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Tuple",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Tuple",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Tuple",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Tuple",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Tuple",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "load_dataset",
        "importPath": "datasets",
        "description": "datasets",
        "isExtraImport": true,
        "detail": "datasets",
        "documentation": {}
    },
    {
        "label": "load_dataset",
        "importPath": "datasets",
        "description": "datasets",
        "isExtraImport": true,
        "detail": "datasets",
        "documentation": {}
    },
    {
        "label": "logging",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "logging",
        "description": "logging",
        "detail": "logging",
        "documentation": {}
    },
    {
        "label": "MedicalLLMEvaluator",
        "importPath": "src.med_llm_evaluation.medical_evaluator",
        "description": "src.med_llm_evaluation.medical_evaluator",
        "isExtraImport": true,
        "detail": "src.med_llm_evaluation.medical_evaluator",
        "documentation": {}
    },
    {
        "label": "MedicalLLMEvaluator",
        "importPath": "src.med_llm_evaluation.medical_evaluator",
        "description": "src.med_llm_evaluation.medical_evaluator",
        "isExtraImport": true,
        "detail": "src.med_llm_evaluation.medical_evaluator",
        "documentation": {}
    },
    {
        "label": "re",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "re",
        "description": "re",
        "detail": "re",
        "documentation": {}
    },
    {
        "label": "random",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "random",
        "description": "random",
        "detail": "random",
        "documentation": {}
    },
    {
        "label": "concurrent.futures",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "concurrent.futures",
        "description": "concurrent.futures",
        "detail": "concurrent.futures",
        "documentation": {}
    },
    {
        "label": "ThreadPoolExecutor",
        "importPath": "concurrent.futures",
        "description": "concurrent.futures",
        "isExtraImport": true,
        "detail": "concurrent.futures",
        "documentation": {}
    },
    {
        "label": "ThreadPoolExecutor",
        "importPath": "concurrent.futures",
        "description": "concurrent.futures",
        "isExtraImport": true,
        "detail": "concurrent.futures",
        "documentation": {}
    },
    {
        "label": "pandas",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "pandas",
        "description": "pandas",
        "detail": "pandas",
        "documentation": {}
    },
    {
        "label": "accuracy_score",
        "importPath": "sklearn.metrics",
        "description": "sklearn.metrics",
        "isExtraImport": true,
        "detail": "sklearn.metrics",
        "documentation": {}
    },
    {
        "label": "confusion_matrix",
        "importPath": "sklearn.metrics",
        "description": "sklearn.metrics",
        "isExtraImport": true,
        "detail": "sklearn.metrics",
        "documentation": {}
    },
    {
        "label": "cohen_kappa_score",
        "importPath": "sklearn.metrics",
        "description": "sklearn.metrics",
        "isExtraImport": true,
        "detail": "sklearn.metrics",
        "documentation": {}
    },
    {
        "label": "accuracy_score",
        "importPath": "sklearn.metrics",
        "description": "sklearn.metrics",
        "isExtraImport": true,
        "detail": "sklearn.metrics",
        "documentation": {}
    },
    {
        "label": "confusion_matrix",
        "importPath": "sklearn.metrics",
        "description": "sklearn.metrics",
        "isExtraImport": true,
        "detail": "sklearn.metrics",
        "documentation": {}
    },
    {
        "label": "cohen_kappa_score",
        "importPath": "sklearn.metrics",
        "description": "sklearn.metrics",
        "isExtraImport": true,
        "detail": "sklearn.metrics",
        "documentation": {}
    },
    {
        "label": "DataHandler",
        "importPath": "src.med_llm_evaluation.data_handler",
        "description": "src.med_llm_evaluation.data_handler",
        "isExtraImport": true,
        "detail": "src.med_llm_evaluation.data_handler",
        "documentation": {}
    },
    {
        "label": "LLMEvaluator",
        "importPath": "src.med_llm_evaluation.llm_evaluator",
        "description": "src.med_llm_evaluation.llm_evaluator",
        "isExtraImport": true,
        "detail": "src.med_llm_evaluation.llm_evaluator",
        "documentation": {}
    },
    {
        "label": "StatisticalAnalyzer",
        "importPath": "src.med_llm_evaluation.statistical_analyzer",
        "description": "src.med_llm_evaluation.statistical_analyzer",
        "isExtraImport": true,
        "detail": "src.med_llm_evaluation.statistical_analyzer",
        "documentation": {}
    },
    {
        "label": "Counter",
        "importPath": "collections",
        "description": "collections",
        "isExtraImport": true,
        "detail": "collections",
        "documentation": {}
    },
    {
        "label": "Counter",
        "importPath": "collections",
        "description": "collections",
        "isExtraImport": true,
        "detail": "collections",
        "documentation": {}
    },
    {
        "label": "scipy.stats",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "scipy.stats",
        "description": "scipy.stats",
        "detail": "scipy.stats",
        "documentation": {}
    },
    {
        "label": "tqdm",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "tqdm",
        "description": "tqdm",
        "detail": "tqdm",
        "documentation": {}
    },
    {
        "label": "time",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "time",
        "description": "time",
        "detail": "time",
        "documentation": {}
    },
    {
        "label": "threading",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "threading",
        "description": "threading",
        "detail": "threading",
        "documentation": {}
    },
    {
        "label": "wraps",
        "importPath": "functools",
        "description": "functools",
        "isExtraImport": true,
        "detail": "functools",
        "documentation": {}
    },
    {
        "label": "sys",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "sys",
        "description": "sys",
        "detail": "sys",
        "documentation": {}
    },
    {
        "label": "PromptDataset",
        "importPath": "src.medhalt.medhalt.models.utils",
        "description": "src.medhalt.medhalt.models.utils",
        "isExtraImport": true,
        "detail": "src.medhalt.medhalt.models.utils",
        "documentation": {}
    },
    {
        "label": "render_navbar",
        "importPath": "components.navbar",
        "description": "components.navbar",
        "isExtraImport": true,
        "detail": "components.navbar",
        "documentation": {}
    },
    {
        "label": "render_footer",
        "importPath": "components.footer",
        "description": "components.footer",
        "isExtraImport": true,
        "detail": "components.footer",
        "documentation": {}
    },
    {
        "label": "render_feature_analysis",
        "importPath": "components.feature_analysis",
        "description": "components.feature_analysis",
        "isExtraImport": true,
        "detail": "components.feature_analysis",
        "documentation": {}
    },
    {
        "label": "render_visualizations",
        "importPath": "components.visualizations",
        "description": "components.visualizations",
        "isExtraImport": true,
        "detail": "components.visualizations",
        "documentation": {}
    },
    {
        "label": "mock_responses",
        "importPath": "utils.utilities",
        "description": "utils.utilities",
        "isExtraImport": true,
        "detail": "utils.utilities",
        "documentation": {}
    },
    {
        "label": "activated_features",
        "importPath": "utils.utilities",
        "description": "utils.utilities",
        "isExtraImport": true,
        "detail": "utils.utilities",
        "documentation": {}
    },
    {
        "label": "split_prompt",
        "importPath": "utils.utilities",
        "description": "utils.utilities",
        "isExtraImport": true,
        "detail": "utils.utilities",
        "documentation": {}
    },
    {
        "label": "DataHandler",
        "importPath": "med_llm_evaluation.data_handler",
        "description": "med_llm_evaluation.data_handler",
        "isExtraImport": true,
        "detail": "med_llm_evaluation.data_handler",
        "documentation": {}
    },
    {
        "label": "client",
        "importPath": "config.config",
        "description": "config.config",
        "isExtraImport": true,
        "detail": "config.config",
        "documentation": {}
    },
    {
        "label": "variant",
        "importPath": "config.config",
        "description": "config.config",
        "isExtraImport": true,
        "detail": "config.config",
        "documentation": {}
    },
    {
        "label": "render_feature_analysis",
        "kind": 2,
        "importPath": "src.components.feature_analysis",
        "description": "src.components.feature_analysis",
        "peekOfCode": "def render_feature_analysis(activated_features):\n    st.markdown(\"---\")\n    st.header(\"Feature Steering and Analysis\")\n    cols = st.columns([2, 3])  # Layout\n    with cols[0]:\n        st.subheader(\"Feature Steering\")\n        sliders = {}\n        for feature in activated_features:\n            sliders[feature] = st.slider(f\"Adjust {feature}:\", min_value=0.0, max_value=1.0, step=0.1, value=0.5)\n    with cols[1]:",
        "detail": "src.components.feature_analysis",
        "documentation": {}
    },
    {
        "label": "render_footer",
        "kind": 2,
        "importPath": "src.components.footer",
        "description": "src.components.footer",
        "peekOfCode": "def render_footer():\n    st.markdown(\n        \"\"\"\n        <style>\n        .full-width-footer {\n            position: fixed;\n            bottom: 0;\n            left: 0;\n            width: 100%;\n            background-color: #333333; /* Dark gray */",
        "detail": "src.components.footer",
        "documentation": {}
    },
    {
        "label": "render_navbar",
        "kind": 2,
        "importPath": "src.components.navbar",
        "description": "src.components.navbar",
        "peekOfCode": "def render_navbar():\n    # st.sidebar.image(\"src/assets/Gradients Anatomy_logo1.webp\", use_container_width=True)\n    st.markdown(\n    \"\"\"\n    <style>\n    .sidebar .sidebar-content {\n        padding: 0;\n    }\n    .nav-link {\n        font-size: 16px;",
        "detail": "src.components.navbar",
        "documentation": {}
    },
    {
        "label": "render_visualizations",
        "kind": 2,
        "importPath": "src.components.visualizations",
        "description": "src.components.visualizations",
        "peekOfCode": "def render_visualizations(activated_features):\n    st.markdown(\"---\")\n    st.header(\"Visualizations\")\n    cols = st.columns([1, 1])\n    with cols[0]:\n        st.subheader(\"Hallucination Probability\")\n        x = np.linspace(0, 1, 10)\n        y = np.sin(x)  # Example data\n        fig, ax = plt.subplots()\n        ax.plot(x, y)",
        "detail": "src.components.visualizations",
        "documentation": {}
    },
    {
        "label": "gf_api_key",
        "kind": 5,
        "importPath": "src.config.config",
        "description": "src.config.config",
        "peekOfCode": "gf_api_key = os.getenv('GOODFIRE_API_KEY')\nclient = goodfire.Client(gf_api_key)\nvariant = goodfire.Variant(\"meta-llama/Meta-Llama-3-8B-Instruct\")",
        "detail": "src.config.config",
        "documentation": {}
    },
    {
        "label": "client",
        "kind": 5,
        "importPath": "src.config.config",
        "description": "src.config.config",
        "peekOfCode": "client = goodfire.Client(gf_api_key)\nvariant = goodfire.Variant(\"meta-llama/Meta-Llama-3-8B-Instruct\")",
        "detail": "src.config.config",
        "documentation": {}
    },
    {
        "label": "variant",
        "kind": 5,
        "importPath": "src.config.config",
        "description": "src.config.config",
        "peekOfCode": "variant = goodfire.Variant(\"meta-llama/Meta-Llama-3-8B-Instruct\")",
        "detail": "src.config.config",
        "documentation": {}
    },
    {
        "label": "DataHandler",
        "kind": 6,
        "importPath": "src.med_llm_evaluation.data_handler",
        "description": "src.med_llm_evaluation.data_handler",
        "peekOfCode": "class DataHandler:\n    \"\"\"Handles loading and preprocessing of medical evaluation data.\"\"\"\n    def __init__(self, cache_dir: str = \".cache/med_eval\"):\n        \"\"\"\n        Initialize DataHandler with cache directory.\n        Args:\n            cache_dir (str): Directory for caching downloaded data\n        \"\"\"\n        self.cache_dir = Path(cache_dir)\n        self.cache_dir.mkdir(parents=True, exist_ok=True)",
        "detail": "src.med_llm_evaluation.data_handler",
        "documentation": {}
    },
    {
        "label": "logger",
        "kind": 5,
        "importPath": "src.med_llm_evaluation.data_handler",
        "description": "src.med_llm_evaluation.data_handler",
        "peekOfCode": "logger = logging.getLogger(__name__)\nclass DataHandler:\n    \"\"\"Handles loading and preprocessing of medical evaluation data.\"\"\"\n    def __init__(self, cache_dir: str = \".cache/med_eval\"):\n        \"\"\"\n        Initialize DataHandler with cache directory.\n        Args:\n            cache_dir (str): Directory for caching downloaded data\n        \"\"\"\n        self.cache_dir = Path(cache_dir)",
        "detail": "src.med_llm_evaluation.data_handler",
        "documentation": {}
    },
    {
        "label": "logger",
        "kind": 5,
        "importPath": "src.med_llm_evaluation.example",
        "description": "src.med_llm_evaluation.example",
        "peekOfCode": "logger = logging.getLogger(__name__)\n# Get API key from environment variable\napi_key = os.getenv('GOODFIRE_API_KEY')\nif not api_key:\n    raise ValueError(\"Please set the GOODFIRE_API_KEY environment variable\")\n# Initialize Goodfire client\nclient = goodfire.Client(api_key)\nvariant = goodfire.Variant(\"meta-llama/Meta-Llama-3-8B-Instruct\")\n# Initialize evaluator\nevaluator = MedicalLLMEvaluator(client, variant)",
        "detail": "src.med_llm_evaluation.example",
        "documentation": {}
    },
    {
        "label": "api_key",
        "kind": 5,
        "importPath": "src.med_llm_evaluation.example",
        "description": "src.med_llm_evaluation.example",
        "peekOfCode": "api_key = os.getenv('GOODFIRE_API_KEY')\nif not api_key:\n    raise ValueError(\"Please set the GOODFIRE_API_KEY environment variable\")\n# Initialize Goodfire client\nclient = goodfire.Client(api_key)\nvariant = goodfire.Variant(\"meta-llama/Meta-Llama-3-8B-Instruct\")\n# Initialize evaluator\nevaluator = MedicalLLMEvaluator(client, variant)\n# Run evaluation\naccuracy, kappa, results, stats = evaluator.run_evaluation(",
        "detail": "src.med_llm_evaluation.example",
        "documentation": {}
    },
    {
        "label": "client",
        "kind": 5,
        "importPath": "src.med_llm_evaluation.example",
        "description": "src.med_llm_evaluation.example",
        "peekOfCode": "client = goodfire.Client(api_key)\nvariant = goodfire.Variant(\"meta-llama/Meta-Llama-3-8B-Instruct\")\n# Initialize evaluator\nevaluator = MedicalLLMEvaluator(client, variant)\n# Run evaluation\naccuracy, kappa, results, stats = evaluator.run_evaluation(\n    k=30,              # number of samples\n    random_seed=42,    # for reproducibility\n    max_workers=10,    # concurrent API calls\n    subject_name=None  # optionally filter by subject",
        "detail": "src.med_llm_evaluation.example",
        "documentation": {}
    },
    {
        "label": "variant",
        "kind": 5,
        "importPath": "src.med_llm_evaluation.example",
        "description": "src.med_llm_evaluation.example",
        "peekOfCode": "variant = goodfire.Variant(\"meta-llama/Meta-Llama-3-8B-Instruct\")\n# Initialize evaluator\nevaluator = MedicalLLMEvaluator(client, variant)\n# Run evaluation\naccuracy, kappa, results, stats = evaluator.run_evaluation(\n    k=30,              # number of samples\n    random_seed=42,    # for reproducibility\n    max_workers=10,    # concurrent API calls\n    subject_name=None  # optionally filter by subject\n)",
        "detail": "src.med_llm_evaluation.example",
        "documentation": {}
    },
    {
        "label": "evaluator",
        "kind": 5,
        "importPath": "src.med_llm_evaluation.example",
        "description": "src.med_llm_evaluation.example",
        "peekOfCode": "evaluator = MedicalLLMEvaluator(client, variant)\n# Run evaluation\naccuracy, kappa, results, stats = evaluator.run_evaluation(\n    k=30,              # number of samples\n    random_seed=42,    # for reproducibility\n    max_workers=10,    # concurrent API calls\n    subject_name=None  # optionally filter by subject\n)\n# Results are already logged by the evaluator\n# You can also access them programmatically:",
        "detail": "src.med_llm_evaluation.example",
        "documentation": {}
    },
    {
        "label": "LLMEvaluator",
        "kind": 6,
        "importPath": "src.med_llm_evaluation.llm_evaluator",
        "description": "src.med_llm_evaluation.llm_evaluator",
        "peekOfCode": "class LLMEvaluator:\n    \"\"\"Handles evaluation of LLM performance on medical questions.\"\"\"\n    def __init__(self, client, variant):\n        \"\"\"\n        Initialize evaluator with API client and variant.\n        Args:\n            client: The API client instance\n            variant: The model variant to use\n        \"\"\"\n        self.variant = variant",
        "detail": "src.med_llm_evaluation.llm_evaluator",
        "documentation": {}
    },
    {
        "label": "logger",
        "kind": 5,
        "importPath": "src.med_llm_evaluation.llm_evaluator",
        "description": "src.med_llm_evaluation.llm_evaluator",
        "peekOfCode": "logger = logging.getLogger(__name__)\nclass LLMEvaluator:\n    \"\"\"Handles evaluation of LLM performance on medical questions.\"\"\"\n    def __init__(self, client, variant):\n        \"\"\"\n        Initialize evaluator with API client and variant.\n        Args:\n            client: The API client instance\n            variant: The model variant to use\n        \"\"\"",
        "detail": "src.med_llm_evaluation.llm_evaluator",
        "documentation": {}
    },
    {
        "label": "MedicalLLMEvaluator",
        "kind": 6,
        "importPath": "src.med_llm_evaluation.medical_evaluator",
        "description": "src.med_llm_evaluation.medical_evaluator",
        "peekOfCode": "class MedicalLLMEvaluator:\n    \"\"\"Main interface for evaluating LLM performance on medical questions.\"\"\"\n    def __init__(self, client, variant, cache_dir: str = \".cache/med_eval\"):\n        \"\"\"\n        Initialize the medical LLM evaluator.\n        Args:\n            client: The API client instance\n            variant: The model variant to use\n            cache_dir (str): Directory for caching downloaded data\n        \"\"\"",
        "detail": "src.med_llm_evaluation.medical_evaluator",
        "documentation": {}
    },
    {
        "label": "logger",
        "kind": 5,
        "importPath": "src.med_llm_evaluation.medical_evaluator",
        "description": "src.med_llm_evaluation.medical_evaluator",
        "peekOfCode": "logger = logging.getLogger(__name__)\nclass MedicalLLMEvaluator:\n    \"\"\"Main interface for evaluating LLM performance on medical questions.\"\"\"\n    def __init__(self, client, variant, cache_dir: str = \".cache/med_eval\"):\n        \"\"\"\n        Initialize the medical LLM evaluator.\n        Args:\n            client: The API client instance\n            variant: The model variant to use\n            cache_dir (str): Directory for caching downloaded data",
        "detail": "src.med_llm_evaluation.medical_evaluator",
        "documentation": {}
    },
    {
        "label": "StatisticalAnalyzer",
        "kind": 6,
        "importPath": "src.med_llm_evaluation.statistical_analyzer",
        "description": "src.med_llm_evaluation.statistical_analyzer",
        "peekOfCode": "class StatisticalAnalyzer:\n    \"\"\"Handles statistical analysis of model performance.\"\"\"\n    @staticmethod\n    def analyze(y_true: List[int], \n                y_pred: List[int], \n                alpha: float = 0.05) -> Dict:\n        \"\"\"\n        Analyze if model performance is significantly better than random.\n        Args:\n            y_true (List[int]): True labels",
        "detail": "src.med_llm_evaluation.statistical_analyzer",
        "documentation": {}
    },
    {
        "label": "logger",
        "kind": 5,
        "importPath": "src.med_llm_evaluation.utils",
        "description": "src.med_llm_evaluation.utils",
        "peekOfCode": "logger = logging.getLogger(__name__)",
        "detail": "src.med_llm_evaluation.utils",
        "documentation": {}
    },
    {
        "label": "RateLimitedExecutor",
        "kind": 6,
        "importPath": "src.notebooks.hallucination_benchmark",
        "description": "src.notebooks.hallucination_benchmark",
        "peekOfCode": "class RateLimitedExecutor:\n    \"\"\"\n    Thread pool executor with rate limiting capabilities.\n    \"\"\"\n    def __init__(self, max_workers=32, requests_per_minute=100):\n        self.max_workers = max_workers\n        self.min_interval = 60.0 / requests_per_minute\n        self.last_request_time = time.time()\n        self.lock = threading.Lock()\n    def wait_for_rate_limit(self):",
        "detail": "src.notebooks.hallucination_benchmark",
        "documentation": {}
    },
    {
        "label": "GoodFireClient",
        "kind": 6,
        "importPath": "src.notebooks.hallucination_benchmark",
        "description": "src.notebooks.hallucination_benchmark",
        "peekOfCode": "class GoodFireClient:\n    def __init__(self, api_key, variant, requests_per_minute=100):\n        self.client = goodfire.Client(api_key)\n        self.variant = variant\n        self.executor = RateLimitedExecutor(\n            max_workers=32,\n            requests_per_minute=requests_per_minute\n        )\n        # Initialize DataFrame with correct columns\n        self.results = pd.DataFrame(columns=['id', 'prompt', 'question', 'options', 'correct_index', 'response', 'hallucinated', 'error'])",
        "detail": "src.notebooks.hallucination_benchmark",
        "documentation": {}
    },
    {
        "label": "exponential_backoff",
        "kind": 2,
        "importPath": "src.notebooks.hallucination_benchmark",
        "description": "src.notebooks.hallucination_benchmark",
        "peekOfCode": "def exponential_backoff(max_retries=5, initial_wait=1, max_wait=60):\n    \"\"\"\n    Decorator that implements exponential backoff for rate-limited functions.\n    Args:\n        max_retries (int): Maximum number of retry attempts\n        initial_wait (float): Initial wait time in seconds\n        max_wait (float): Maximum wait time in seconds\n    \"\"\"\n    def decorator(func):\n        @wraps(func)",
        "detail": "src.notebooks.hallucination_benchmark",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "src.notebooks.hallucination_benchmark",
        "description": "src.notebooks.hallucination_benchmark",
        "peekOfCode": "def main():\n    # Load dataset\n    dataset_name = \"FCT\"\n    base_model_name = \"meta-llama/Meta-Llama-3-8B-Instruct\"\n    rate_limit = 99  # Requests per minute\n    fct_ds = PromptDataset(dataset_name=dataset_name, prompt_template_fn=lambda x: x)\n    # Sample the first 10000 rows\n    sampled_fct_ds = fct_ds[:10000]\n    # Initialize GoodFire client\n    variant = goodfire.Variant(base_model_name)",
        "detail": "src.notebooks.hallucination_benchmark",
        "documentation": {}
    },
    {
        "label": "GOODFIRE_API_KEY",
        "kind": 5,
        "importPath": "src.notebooks.hallucination_benchmark",
        "description": "src.notebooks.hallucination_benchmark",
        "peekOfCode": "GOODFIRE_API_KEY = os.getenv('GOODFIRE_API_KEY')\ndef exponential_backoff(max_retries=5, initial_wait=1, max_wait=60):\n    \"\"\"\n    Decorator that implements exponential backoff for rate-limited functions.\n    Args:\n        max_retries (int): Maximum number of retry attempts\n        initial_wait (float): Initial wait time in seconds\n        max_wait (float): Maximum wait time in seconds\n    \"\"\"\n    def decorator(func):",
        "detail": "src.notebooks.hallucination_benchmark",
        "documentation": {}
    },
    {
        "label": "split_prompt",
        "kind": 2,
        "importPath": "src.utils.utilities",
        "description": "src.utils.utilities",
        "peekOfCode": "def split_prompt(prompts):\n  system_prompt = ''\n  user_prompts = [] \n  for prompt in prompts:\n    split_index = prompt.find('[0,1,2,3].') + len('[0,1,2,3].')\n    system_prompt = prompt[:split_index].strip()\n    user_prompt = prompt[split_index:].strip()\n    user_prompts.append(user_prompt)\n  return system_prompt, user_prompts\nmock_responses = {",
        "detail": "src.utils.utilities",
        "documentation": {}
    },
    {
        "label": "mock_responses",
        "kind": 5,
        "importPath": "src.utils.utilities",
        "description": "src.utils.utilities",
        "peekOfCode": "mock_responses = {\n    \"What are the symptoms of diabetes?\": \"The common symptoms of diabetes include increased thirst, frequent urination, extreme fatigue, and blurry vision.\",\n    \"How to treat high blood pressure?\": \"High blood pressure can be managed with lifestyle changes such as reducing salt intake, regular exercise, and medications like ACE inhibitors.\",\n    \"What are common causes of fatigue?\": \"Common causes of fatigue include stress, poor sleep quality, anemia, and chronic medical conditions like hypothyroidism.\"\n}\nactivated_features = [\"Feature A\", \"Feature B\", \"Feature C\"]",
        "detail": "src.utils.utilities",
        "documentation": {}
    },
    {
        "label": "activated_features",
        "kind": 5,
        "importPath": "src.utils.utilities",
        "description": "src.utils.utilities",
        "peekOfCode": "activated_features = [\"Feature A\", \"Feature B\", \"Feature C\"]",
        "detail": "src.utils.utilities",
        "documentation": {}
    },
    {
        "label": "logger",
        "kind": 5,
        "importPath": "src.app",
        "description": "src.app",
        "peekOfCode": "logger = logging.getLogger(__name__)\nrender_navbar()\nst.title(\"Diagnostics Page\")\nst.markdown(\"Refine model outputs using feature steering and analyze response quality.\")\nst.markdown(\"---\")\nst.header(\"Model Inference\")\ndata_handler = DataHandler()\nprompts, labels, subject_names = data_handler.load_data()\nprompts_with_labels = dict(zip(prompts, labels))\nsystem_prompt, user_prompts = split_prompt(prompts[:10])",
        "detail": "src.app",
        "documentation": {}
    },
    {
        "label": "data_handler",
        "kind": 5,
        "importPath": "src.app",
        "description": "src.app",
        "peekOfCode": "data_handler = DataHandler()\nprompts, labels, subject_names = data_handler.load_data()\nprompts_with_labels = dict(zip(prompts, labels))\nsystem_prompt, user_prompts = split_prompt(prompts[:10])\ncols = st.columns([3, 1])  \nwith cols[0]:\n    selected_prompt = st.selectbox(\"Select a predefined question:\", user_prompts)\n    selected_user_prompt = system_prompt + \"\\n\\n\" + selected_prompt\n    ground_truth_label = prompts_with_labels[selected_user_prompt]\n    if st.button(\"Submit Query\"):",
        "detail": "src.app",
        "documentation": {}
    },
    {
        "label": "prompts_with_labels",
        "kind": 5,
        "importPath": "src.app",
        "description": "src.app",
        "peekOfCode": "prompts_with_labels = dict(zip(prompts, labels))\nsystem_prompt, user_prompts = split_prompt(prompts[:10])\ncols = st.columns([3, 1])  \nwith cols[0]:\n    selected_prompt = st.selectbox(\"Select a predefined question:\", user_prompts)\n    selected_user_prompt = system_prompt + \"\\n\\n\" + selected_prompt\n    ground_truth_label = prompts_with_labels[selected_user_prompt]\n    if st.button(\"Submit Query\"):\n        response_text = \"\"\n        try: ",
        "detail": "src.app",
        "documentation": {}
    },
    {
        "label": "cols",
        "kind": 5,
        "importPath": "src.app",
        "description": "src.app",
        "peekOfCode": "cols = st.columns([3, 1])  \nwith cols[0]:\n    selected_prompt = st.selectbox(\"Select a predefined question:\", user_prompts)\n    selected_user_prompt = system_prompt + \"\\n\\n\" + selected_prompt\n    ground_truth_label = prompts_with_labels[selected_user_prompt]\n    if st.button(\"Submit Query\"):\n        response_text = \"\"\n        try: \n           response = client.chat.completions.create(\n             messages=[{\"role\": 'user', \"content\": selected_user_prompt}],",
        "detail": "src.app",
        "documentation": {}
    }
]