[
    {
        "label": "pickle",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "pickle",
        "description": "pickle",
        "detail": "pickle",
        "documentation": {}
    },
    {
        "label": "goodfire",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "goodfire",
        "description": "goodfire",
        "detail": "goodfire",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Tuple",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Tuple",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Tuple",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Tuple",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Tuple",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Tuple",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Tuple",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "numpy",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "numpy",
        "description": "numpy",
        "detail": "numpy",
        "documentation": {}
    },
    {
        "label": "sklearn",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "sklearn",
        "description": "sklearn",
        "detail": "sklearn",
        "documentation": {}
    },
    {
        "label": "streamlit",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "streamlit",
        "description": "streamlit",
        "detail": "streamlit",
        "documentation": {}
    },
    {
        "label": "matplotlib.pyplot",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "matplotlib.pyplot",
        "description": "matplotlib.pyplot",
        "detail": "matplotlib.pyplot",
        "documentation": {}
    },
    {
        "label": "os",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "os",
        "description": "os",
        "detail": "os",
        "documentation": {}
    },
    {
        "label": "HallucinationClassifier",
        "importPath": "src.classifier.hallucination_classifier",
        "description": "src.classifier.hallucination_classifier",
        "isExtraImport": true,
        "detail": "src.classifier.hallucination_classifier",
        "documentation": {}
    },
    {
        "label": "gf_api_key",
        "importPath": "config.config",
        "description": "config.config",
        "isExtraImport": true,
        "detail": "config.config",
        "documentation": {}
    },
    {
        "label": "client",
        "importPath": "config.config",
        "description": "config.config",
        "isExtraImport": true,
        "detail": "config.config",
        "documentation": {}
    },
    {
        "label": "variant",
        "importPath": "config.config",
        "description": "config.config",
        "isExtraImport": true,
        "detail": "config.config",
        "documentation": {}
    },
    {
        "label": "load_dotenv",
        "importPath": "dotenv",
        "description": "dotenv",
        "isExtraImport": true,
        "detail": "dotenv",
        "documentation": {}
    },
    {
        "label": "load_dotenv",
        "importPath": "dotenv",
        "description": "dotenv",
        "isExtraImport": true,
        "detail": "dotenv",
        "documentation": {}
    },
    {
        "label": "load_dotenv",
        "importPath": "dotenv",
        "description": "dotenv",
        "isExtraImport": true,
        "detail": "dotenv",
        "documentation": {}
    },
    {
        "label": "load_dotenv",
        "importPath": "dotenv",
        "description": "dotenv",
        "isExtraImport": true,
        "detail": "dotenv",
        "documentation": {}
    },
    {
        "label": "argparse",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "argparse",
        "description": "argparse",
        "detail": "argparse",
        "documentation": {}
    },
    {
        "label": "asyncio",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "asyncio",
        "description": "asyncio",
        "detail": "asyncio",
        "documentation": {}
    },
    {
        "label": "pandas",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "pandas",
        "description": "pandas",
        "detail": "pandas",
        "documentation": {}
    },
    {
        "label": "load_features",
        "importPath": "src.hallucination_llm_evaluation.utils",
        "description": "src.hallucination_llm_evaluation.utils",
        "isExtraImport": true,
        "detail": "src.hallucination_llm_evaluation.utils",
        "documentation": {}
    },
    {
        "label": "load_features",
        "importPath": "src.hallucination_llm_evaluation.utils",
        "description": "src.hallucination_llm_evaluation.utils",
        "isExtraImport": true,
        "detail": "src.hallucination_llm_evaluation.utils",
        "documentation": {}
    },
    {
        "label": "load_features",
        "importPath": "src.hallucination_llm_evaluation.utils",
        "description": "src.hallucination_llm_evaluation.utils",
        "isExtraImport": true,
        "detail": "src.hallucination_llm_evaluation.utils",
        "documentation": {}
    },
    {
        "label": "PromptDataset",
        "importPath": "src.medhalt.medhalt.models.utils",
        "description": "src.medhalt.medhalt.models.utils",
        "isExtraImport": true,
        "detail": "src.medhalt.medhalt.models.utils",
        "documentation": {}
    },
    {
        "label": "PromptDataset",
        "importPath": "src.medhalt.medhalt.models.utils",
        "description": "src.medhalt.medhalt.models.utils",
        "isExtraImport": true,
        "detail": "src.medhalt.medhalt.models.utils",
        "documentation": {}
    },
    {
        "label": "PromptDataset",
        "importPath": "src.medhalt.medhalt.models.utils",
        "description": "src.medhalt.medhalt.models.utils",
        "isExtraImport": true,
        "detail": "src.medhalt.medhalt.models.utils",
        "documentation": {}
    },
    {
        "label": "AsyncMedicalLLMEvaluator",
        "importPath": "src.med_llm_evaluation.medical_evaluator",
        "description": "src.med_llm_evaluation.medical_evaluator",
        "isExtraImport": true,
        "detail": "src.med_llm_evaluation.medical_evaluator",
        "documentation": {}
    },
    {
        "label": "AsyncMedicalLLMEvaluator",
        "importPath": "src.med_llm_evaluation.medical_evaluator",
        "description": "src.med_llm_evaluation.medical_evaluator",
        "isExtraImport": true,
        "detail": "src.med_llm_evaluation.medical_evaluator",
        "documentation": {}
    },
    {
        "label": "AsyncMedicalLLMEvaluator",
        "importPath": "src.med_llm_evaluation.medical_evaluator",
        "description": "src.med_llm_evaluation.medical_evaluator",
        "isExtraImport": true,
        "detail": "src.med_llm_evaluation.medical_evaluator",
        "documentation": {}
    },
    {
        "label": "MedicalLLMEvaluator",
        "importPath": "src.med_llm_evaluation.medical_evaluator",
        "description": "src.med_llm_evaluation.medical_evaluator",
        "isExtraImport": true,
        "detail": "src.med_llm_evaluation.medical_evaluator",
        "documentation": {}
    },
    {
        "label": "AsyncGoodFireClient",
        "importPath": "src.hallucination_llm_evaluation.hallucination_benchmark",
        "description": "src.hallucination_llm_evaluation.hallucination_benchmark",
        "isExtraImport": true,
        "detail": "src.hallucination_llm_evaluation.hallucination_benchmark",
        "documentation": {}
    },
    {
        "label": "GOODFIRE_API_KEY",
        "importPath": "src.hallucination_llm_evaluation.hallucination_benchmark",
        "description": "src.hallucination_llm_evaluation.hallucination_benchmark",
        "isExtraImport": true,
        "detail": "src.hallucination_llm_evaluation.hallucination_benchmark",
        "documentation": {}
    },
    {
        "label": "RATE_LIMIT",
        "importPath": "src.hallucination_llm_evaluation.hallucination_benchmark",
        "description": "src.hallucination_llm_evaluation.hallucination_benchmark",
        "isExtraImport": true,
        "detail": "src.hallucination_llm_evaluation.hallucination_benchmark",
        "documentation": {}
    },
    {
        "label": "MODEL_NAME",
        "importPath": "src.hallucination_llm_evaluation.hallucination_benchmark",
        "description": "src.hallucination_llm_evaluation.hallucination_benchmark",
        "isExtraImport": true,
        "detail": "src.hallucination_llm_evaluation.hallucination_benchmark",
        "documentation": {}
    },
    {
        "label": "AsyncGoodFireClient",
        "importPath": "src.hallucination_llm_evaluation.hallucination_benchmark",
        "description": "src.hallucination_llm_evaluation.hallucination_benchmark",
        "isExtraImport": true,
        "detail": "src.hallucination_llm_evaluation.hallucination_benchmark",
        "documentation": {}
    },
    {
        "label": "tqdm",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "tqdm",
        "description": "tqdm",
        "detail": "tqdm",
        "documentation": {}
    },
    {
        "label": "time",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "time",
        "description": "time",
        "detail": "time",
        "documentation": {}
    },
    {
        "label": "random",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "random",
        "description": "random",
        "detail": "random",
        "documentation": {}
    },
    {
        "label": "wraps",
        "importPath": "functools",
        "description": "functools",
        "isExtraImport": true,
        "detail": "functools",
        "documentation": {}
    },
    {
        "label": "ast",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "ast",
        "description": "ast",
        "detail": "ast",
        "documentation": {}
    },
    {
        "label": "literal_eval",
        "importPath": "ast",
        "description": "ast",
        "isExtraImport": true,
        "detail": "ast",
        "documentation": {}
    },
    {
        "label": "re",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "re",
        "description": "re",
        "detail": "re",
        "documentation": {}
    },
    {
        "label": "sys",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "sys",
        "description": "sys",
        "detail": "sys",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "json",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "json",
        "description": "json",
        "detail": "json",
        "documentation": {}
    },
    {
        "label": "load_dataset",
        "importPath": "datasets",
        "description": "datasets",
        "isExtraImport": true,
        "detail": "datasets",
        "documentation": {}
    },
    {
        "label": "load_dataset",
        "importPath": "datasets",
        "description": "datasets",
        "isExtraImport": true,
        "detail": "datasets",
        "documentation": {}
    },
    {
        "label": "logging",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "logging",
        "description": "logging",
        "detail": "logging",
        "documentation": {}
    },
    {
        "label": "accuracy_score",
        "importPath": "sklearn.metrics",
        "description": "sklearn.metrics",
        "isExtraImport": true,
        "detail": "sklearn.metrics",
        "documentation": {}
    },
    {
        "label": "confusion_matrix",
        "importPath": "sklearn.metrics",
        "description": "sklearn.metrics",
        "isExtraImport": true,
        "detail": "sklearn.metrics",
        "documentation": {}
    },
    {
        "label": "cohen_kappa_score",
        "importPath": "sklearn.metrics",
        "description": "sklearn.metrics",
        "isExtraImport": true,
        "detail": "sklearn.metrics",
        "documentation": {}
    },
    {
        "label": "accuracy_score",
        "importPath": "sklearn.metrics",
        "description": "sklearn.metrics",
        "isExtraImport": true,
        "detail": "sklearn.metrics",
        "documentation": {}
    },
    {
        "label": "confusion_matrix",
        "importPath": "sklearn.metrics",
        "description": "sklearn.metrics",
        "isExtraImport": true,
        "detail": "sklearn.metrics",
        "documentation": {}
    },
    {
        "label": "cohen_kappa_score",
        "importPath": "sklearn.metrics",
        "description": "sklearn.metrics",
        "isExtraImport": true,
        "detail": "sklearn.metrics",
        "documentation": {}
    },
    {
        "label": "DataHandler",
        "importPath": "src.med_llm_evaluation.data_handler",
        "description": "src.med_llm_evaluation.data_handler",
        "isExtraImport": true,
        "detail": "src.med_llm_evaluation.data_handler",
        "documentation": {}
    },
    {
        "label": "AsyncLLMEvaluator",
        "importPath": "src.med_llm_evaluation.llm_evaluator",
        "description": "src.med_llm_evaluation.llm_evaluator",
        "isExtraImport": true,
        "detail": "src.med_llm_evaluation.llm_evaluator",
        "documentation": {}
    },
    {
        "label": "StatisticalAnalyzer",
        "importPath": "src.med_llm_evaluation.statistical_analyzer",
        "description": "src.med_llm_evaluation.statistical_analyzer",
        "isExtraImport": true,
        "detail": "src.med_llm_evaluation.statistical_analyzer",
        "documentation": {}
    },
    {
        "label": "Counter",
        "importPath": "collections",
        "description": "collections",
        "isExtraImport": true,
        "detail": "collections",
        "documentation": {}
    },
    {
        "label": "Counter",
        "importPath": "collections",
        "description": "collections",
        "isExtraImport": true,
        "detail": "collections",
        "documentation": {}
    },
    {
        "label": "scipy.stats",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "scipy.stats",
        "description": "scipy.stats",
        "detail": "scipy.stats",
        "documentation": {}
    },
    {
        "label": "ThreadPoolExecutor",
        "importPath": "concurrent.futures",
        "description": "concurrent.futures",
        "isExtraImport": true,
        "detail": "concurrent.futures",
        "documentation": {}
    },
    {
        "label": "render_navbar",
        "importPath": "components.navbar",
        "description": "components.navbar",
        "isExtraImport": true,
        "detail": "components.navbar",
        "documentation": {}
    },
    {
        "label": "render_footer",
        "importPath": "components.footer",
        "description": "components.footer",
        "isExtraImport": true,
        "detail": "components.footer",
        "documentation": {}
    },
    {
        "label": "render_feature_analysis",
        "importPath": "components.feature_analysis",
        "description": "components.feature_analysis",
        "isExtraImport": true,
        "detail": "components.feature_analysis",
        "documentation": {}
    },
    {
        "label": "render_hallucination_detector",
        "importPath": "components.hallucination_detector",
        "description": "components.hallucination_detector",
        "isExtraImport": true,
        "detail": "components.hallucination_detector",
        "documentation": {}
    },
    {
        "label": "render_visualizations",
        "importPath": "components.visualizations",
        "description": "components.visualizations",
        "isExtraImport": true,
        "detail": "components.visualizations",
        "documentation": {}
    },
    {
        "label": "DataHandler",
        "importPath": "med_llm_evaluation.data_handler",
        "description": "med_llm_evaluation.data_handler",
        "isExtraImport": true,
        "detail": "med_llm_evaluation.data_handler",
        "documentation": {}
    },
    {
        "label": "split_prompt",
        "importPath": "utils.utilities",
        "description": "utils.utilities",
        "isExtraImport": true,
        "detail": "utils.utilities",
        "documentation": {}
    },
    {
        "label": "activated_features",
        "importPath": "utils.utilities",
        "description": "utils.utilities",
        "isExtraImport": true,
        "detail": "utils.utilities",
        "documentation": {}
    },
    {
        "label": "HallucinationClassifier",
        "kind": 6,
        "importPath": "src.classifier.hallucination_classifier",
        "description": "src.classifier.hallucination_classifier",
        "peekOfCode": "class HallucinationClassifier:\n    def __init__(self, model_path: str, api_key: str):\n        \"\"\"\n        Initialize the hallucination classifier with a saved model and features.\n        Args:\n            model_path: Path to the saved pickle file containing both the model and features\n            api_key: Goodfire API key for accessing the service\n        \"\"\"\n        # Load the model and features\n        with open(model_path, 'rb') as f:",
        "detail": "src.classifier.hallucination_classifier",
        "documentation": {}
    },
    {
        "label": "SVMHallucinationClassifier",
        "kind": 6,
        "importPath": "src.classifier.hallucination_classifier_svm",
        "description": "src.classifier.hallucination_classifier_svm",
        "peekOfCode": "class SVMHallucinationClassifier:\n    def __init__(self, model_path: str, api_key: str):\n        \"\"\"\n        Initialize the hallucination classifier with a saved SVM model and features.\n        Args:\n            model_path: Path to the saved pickle file containing both the model and features\n            api_key: Goodfire API key for accessing the service\n        \"\"\"\n        # Load the model and features\n        with open(model_path, 'rb') as f:",
        "detail": "src.classifier.hallucination_classifier_svm",
        "documentation": {}
    },
    {
        "label": "render_feature_analysis",
        "kind": 2,
        "importPath": "src.components.feature_analysis",
        "description": "src.components.feature_analysis",
        "peekOfCode": "def render_feature_analysis(activated_features):\n    st.markdown(\"---\")\n    st.header(\"Feature Steering and Analysis\")\n    cols = st.columns([2, 3])  # Layout\n    with cols[0]:\n        st.subheader(\"Feature Steering\")\n        sliders = {}\n        for feature in activated_features:\n            sliders[feature] = st.slider(f\"Adjust {feature}:\", min_value=0.0, max_value=1.0, step=0.1, value=0.5)\n    with cols[1]:",
        "detail": "src.components.feature_analysis",
        "documentation": {}
    },
    {
        "label": "render_footer",
        "kind": 2,
        "importPath": "src.components.footer",
        "description": "src.components.footer",
        "peekOfCode": "def render_footer():\n    st.markdown(\n        \"\"\"\n        <style>\n        .full-width-footer {\n            position: fixed;\n            bottom: 0;\n            left: 0;\n            width: 100%;\n            background-color: #333333; /* Dark gray */",
        "detail": "src.components.footer",
        "documentation": {}
    },
    {
        "label": "render_hallucination_detector",
        "kind": 2,
        "importPath": "src.components.hallucination_detector",
        "description": "src.components.hallucination_detector",
        "peekOfCode": "def render_hallucination_detector(prompt):\n  model_path = \"src/classifier/hallucination_classifier_svm.pkl\"\n  st.markdown('--')\n  st.header(\"Hallucination Detection\")\n  classifier = HallucinationClassifier(model_path=model_path, api_key=gf_api_key)\n  prediction, confidence = classifier.predict(prompt, debug=False)\n  result = \"Hallucinated\" if prediction == 1 else \"Truthful\"\n  st.success(f\"Prediction: {result}\") if result == \"Truthful\" else st.warning(f\"Prediction: {result}\")\n  st.info(f\"I am: {confidence * 100:.2f}% confident\")",
        "detail": "src.components.hallucination_detector",
        "documentation": {}
    },
    {
        "label": "render_navbar",
        "kind": 2,
        "importPath": "src.components.navbar",
        "description": "src.components.navbar",
        "peekOfCode": "def render_navbar():\n    # st.sidebar.image(\"src/assets/Gradients Anatomy_logo1.webp\", use_container_width=True)\n    st.markdown(\n    \"\"\"\n    <style>\n    .sidebar .sidebar-content {\n        padding: 0;\n    }\n    .nav-link {\n        font-size: 16px;",
        "detail": "src.components.navbar",
        "documentation": {}
    },
    {
        "label": "render_visualizations",
        "kind": 2,
        "importPath": "src.components.visualizations",
        "description": "src.components.visualizations",
        "peekOfCode": "def render_visualizations(activated_features):\n    st.markdown(\"---\")\n    st.header(\"Visualizations\")\n    cols = st.columns([1, 1])\n    with cols[0]:\n        st.subheader(\"Hallucination Probability\")\n        x = np.linspace(0, 1, 10)\n        y = np.sin(x)  # Example data\n        fig, ax = plt.subplots()\n        ax.plot(x, y)",
        "detail": "src.components.visualizations",
        "documentation": {}
    },
    {
        "label": "gf_api_key",
        "kind": 5,
        "importPath": "src.config.config",
        "description": "src.config.config",
        "peekOfCode": "gf_api_key = os.getenv('GOODFIRE_API_KEY')\nclient = goodfire.Client(gf_api_key)\nvariant = goodfire.Variant(\"meta-llama/Meta-Llama-3-8B-Instruct\")",
        "detail": "src.config.config",
        "documentation": {}
    },
    {
        "label": "client",
        "kind": 5,
        "importPath": "src.config.config",
        "description": "src.config.config",
        "peekOfCode": "client = goodfire.Client(gf_api_key)\nvariant = goodfire.Variant(\"meta-llama/Meta-Llama-3-8B-Instruct\")",
        "detail": "src.config.config",
        "documentation": {}
    },
    {
        "label": "variant",
        "kind": 5,
        "importPath": "src.config.config",
        "description": "src.config.config",
        "peekOfCode": "variant = goodfire.Variant(\"meta-llama/Meta-Llama-3-8B-Instruct\")",
        "detail": "src.config.config",
        "documentation": {}
    },
    {
        "label": "get_hallucination_rate",
        "kind": 2,
        "importPath": "src.hallucination_llm_evaluation.feature_steering_hallucination",
        "description": "src.hallucination_llm_evaluation.feature_steering_hallucination",
        "peekOfCode": "def get_hallucination_rate(df: pd.DataFrame):\n    \"\"\"Calculate the hallucination rate for the results dataframe.\"\"\"\n    # Plot the hallucination rate for each feature activation\n    hallucination_rates = {}\n    for feature_activation in df['feature_activation'].unique():\n        feature_activation_df = df[df['feature_activation'] == feature_activation]\n        hallucination_rate = len(feature_activation_df[feature_activation_df['hallucinated'] == True]) / len(feature_activation_df['hallucinated'].dropna())\n        hallucination_rates[feature_activation] = hallucination_rate\n    hallucination_rates_df = pd.DataFrame(hallucination_rates.items(), columns=['feature_activation', 'hallucination_rate'])\n    # Get the hallucination counts for each feature activation",
        "detail": "src.hallucination_llm_evaluation.feature_steering_hallucination",
        "documentation": {}
    },
    {
        "label": "GOODFIRE_API_KEY",
        "kind": 5,
        "importPath": "src.hallucination_llm_evaluation.feature_steering_hallucination",
        "description": "src.hallucination_llm_evaluation.feature_steering_hallucination",
        "peekOfCode": "GOODFIRE_API_KEY = os.getenv('GOODFIRE_API_KEY')\nRATE_LIMIT = 99\nFEATURES_PATH = 'src/hallucination_llm_evaluation/relevant_features.json'\nMODEL_NAME = \"meta-llama/Llama-3.3-70B-Instruct\"\ndef get_hallucination_rate(df: pd.DataFrame):\n    \"\"\"Calculate the hallucination rate for the results dataframe.\"\"\"\n    # Plot the hallucination rate for each feature activation\n    hallucination_rates = {}\n    for feature_activation in df['feature_activation'].unique():\n        feature_activation_df = df[df['feature_activation'] == feature_activation]",
        "detail": "src.hallucination_llm_evaluation.feature_steering_hallucination",
        "documentation": {}
    },
    {
        "label": "RATE_LIMIT",
        "kind": 5,
        "importPath": "src.hallucination_llm_evaluation.feature_steering_hallucination",
        "description": "src.hallucination_llm_evaluation.feature_steering_hallucination",
        "peekOfCode": "RATE_LIMIT = 99\nFEATURES_PATH = 'src/hallucination_llm_evaluation/relevant_features.json'\nMODEL_NAME = \"meta-llama/Llama-3.3-70B-Instruct\"\ndef get_hallucination_rate(df: pd.DataFrame):\n    \"\"\"Calculate the hallucination rate for the results dataframe.\"\"\"\n    # Plot the hallucination rate for each feature activation\n    hallucination_rates = {}\n    for feature_activation in df['feature_activation'].unique():\n        feature_activation_df = df[df['feature_activation'] == feature_activation]\n        hallucination_rate = len(feature_activation_df[feature_activation_df['hallucinated'] == True]) / len(feature_activation_df['hallucinated'].dropna())",
        "detail": "src.hallucination_llm_evaluation.feature_steering_hallucination",
        "documentation": {}
    },
    {
        "label": "FEATURES_PATH",
        "kind": 5,
        "importPath": "src.hallucination_llm_evaluation.feature_steering_hallucination",
        "description": "src.hallucination_llm_evaluation.feature_steering_hallucination",
        "peekOfCode": "FEATURES_PATH = 'src/hallucination_llm_evaluation/relevant_features.json'\nMODEL_NAME = \"meta-llama/Llama-3.3-70B-Instruct\"\ndef get_hallucination_rate(df: pd.DataFrame):\n    \"\"\"Calculate the hallucination rate for the results dataframe.\"\"\"\n    # Plot the hallucination rate for each feature activation\n    hallucination_rates = {}\n    for feature_activation in df['feature_activation'].unique():\n        feature_activation_df = df[df['feature_activation'] == feature_activation]\n        hallucination_rate = len(feature_activation_df[feature_activation_df['hallucinated'] == True]) / len(feature_activation_df['hallucinated'].dropna())\n        hallucination_rates[feature_activation] = hallucination_rate",
        "detail": "src.hallucination_llm_evaluation.feature_steering_hallucination",
        "documentation": {}
    },
    {
        "label": "MODEL_NAME",
        "kind": 5,
        "importPath": "src.hallucination_llm_evaluation.feature_steering_hallucination",
        "description": "src.hallucination_llm_evaluation.feature_steering_hallucination",
        "peekOfCode": "MODEL_NAME = \"meta-llama/Llama-3.3-70B-Instruct\"\ndef get_hallucination_rate(df: pd.DataFrame):\n    \"\"\"Calculate the hallucination rate for the results dataframe.\"\"\"\n    # Plot the hallucination rate for each feature activation\n    hallucination_rates = {}\n    for feature_activation in df['feature_activation'].unique():\n        feature_activation_df = df[df['feature_activation'] == feature_activation]\n        hallucination_rate = len(feature_activation_df[feature_activation_df['hallucinated'] == True]) / len(feature_activation_df['hallucinated'].dropna())\n        hallucination_rates[feature_activation] = hallucination_rate\n    hallucination_rates_df = pd.DataFrame(hallucination_rates.items(), columns=['feature_activation', 'hallucination_rate'])",
        "detail": "src.hallucination_llm_evaluation.feature_steering_hallucination",
        "documentation": {}
    },
    {
        "label": "AsyncRateLimiter",
        "kind": 6,
        "importPath": "src.hallucination_llm_evaluation.hallucination_benchmark",
        "description": "src.hallucination_llm_evaluation.hallucination_benchmark",
        "peekOfCode": "class AsyncRateLimiter:\n    \"\"\"Async rate limiter using a semaphore and sliding window\"\"\"\n    def __init__(self, requests_per_minute: int):\n        self.semaphore = asyncio.Semaphore(requests_per_minute)\n        self.request_times = []\n        self.window_size = 60  # 1 minute window\n        self.requests_per_minute = requests_per_minute\n        self.lock = asyncio.Lock()\n    async def acquire(self):\n        \"\"\"Acquire rate limit token\"\"\"",
        "detail": "src.hallucination_llm_evaluation.hallucination_benchmark",
        "documentation": {}
    },
    {
        "label": "AsyncGoodFireClient",
        "kind": 6,
        "importPath": "src.hallucination_llm_evaluation.hallucination_benchmark",
        "description": "src.hallucination_llm_evaluation.hallucination_benchmark",
        "peekOfCode": "class AsyncGoodFireClient:\n    def __init__(self, api_key: str, variant: goodfire.Variant, requests_per_minute=100, batch_size=10):\n        self.client = goodfire.AsyncClient(api_key)\n        self.variant = variant\n        self.rate_limiter = AsyncRateLimiter(requests_per_minute)\n        self.batch_size = batch_size\n        self.feature_activation = 0\n        # Initialize DataFrame with correct columns\n        self.results = pd.DataFrame(columns=[\n            'id', 'feature_activation', 'prompt', 'question', 'options',",
        "detail": "src.hallucination_llm_evaluation.hallucination_benchmark",
        "documentation": {}
    },
    {
        "label": "GOODFIRE_API_KEY",
        "kind": 5,
        "importPath": "src.hallucination_llm_evaluation.hallucination_benchmark",
        "description": "src.hallucination_llm_evaluation.hallucination_benchmark",
        "peekOfCode": "GOODFIRE_API_KEY = os.getenv('GOODFIRE_API_KEY')\nRATE_LIMIT = 99\nFEATURES_PATH = 'src/hallucination_llm_evaluation/relevant_features.json'\nMODEL_NAME = \"meta-llama/Llama-3.3-70B-Instruct\"\nclass AsyncRateLimiter:\n    \"\"\"Async rate limiter using a semaphore and sliding window\"\"\"\n    def __init__(self, requests_per_minute: int):\n        self.semaphore = asyncio.Semaphore(requests_per_minute)\n        self.request_times = []\n        self.window_size = 60  # 1 minute window",
        "detail": "src.hallucination_llm_evaluation.hallucination_benchmark",
        "documentation": {}
    },
    {
        "label": "RATE_LIMIT",
        "kind": 5,
        "importPath": "src.hallucination_llm_evaluation.hallucination_benchmark",
        "description": "src.hallucination_llm_evaluation.hallucination_benchmark",
        "peekOfCode": "RATE_LIMIT = 99\nFEATURES_PATH = 'src/hallucination_llm_evaluation/relevant_features.json'\nMODEL_NAME = \"meta-llama/Llama-3.3-70B-Instruct\"\nclass AsyncRateLimiter:\n    \"\"\"Async rate limiter using a semaphore and sliding window\"\"\"\n    def __init__(self, requests_per_minute: int):\n        self.semaphore = asyncio.Semaphore(requests_per_minute)\n        self.request_times = []\n        self.window_size = 60  # 1 minute window\n        self.requests_per_minute = requests_per_minute",
        "detail": "src.hallucination_llm_evaluation.hallucination_benchmark",
        "documentation": {}
    },
    {
        "label": "FEATURES_PATH",
        "kind": 5,
        "importPath": "src.hallucination_llm_evaluation.hallucination_benchmark",
        "description": "src.hallucination_llm_evaluation.hallucination_benchmark",
        "peekOfCode": "FEATURES_PATH = 'src/hallucination_llm_evaluation/relevant_features.json'\nMODEL_NAME = \"meta-llama/Llama-3.3-70B-Instruct\"\nclass AsyncRateLimiter:\n    \"\"\"Async rate limiter using a semaphore and sliding window\"\"\"\n    def __init__(self, requests_per_minute: int):\n        self.semaphore = asyncio.Semaphore(requests_per_minute)\n        self.request_times = []\n        self.window_size = 60  # 1 minute window\n        self.requests_per_minute = requests_per_minute\n        self.lock = asyncio.Lock()",
        "detail": "src.hallucination_llm_evaluation.hallucination_benchmark",
        "documentation": {}
    },
    {
        "label": "MODEL_NAME",
        "kind": 5,
        "importPath": "src.hallucination_llm_evaluation.hallucination_benchmark",
        "description": "src.hallucination_llm_evaluation.hallucination_benchmark",
        "peekOfCode": "MODEL_NAME = \"meta-llama/Llama-3.3-70B-Instruct\"\nclass AsyncRateLimiter:\n    \"\"\"Async rate limiter using a semaphore and sliding window\"\"\"\n    def __init__(self, requests_per_minute: int):\n        self.semaphore = asyncio.Semaphore(requests_per_minute)\n        self.request_times = []\n        self.window_size = 60  # 1 minute window\n        self.requests_per_minute = requests_per_minute\n        self.lock = asyncio.Lock()\n    async def acquire(self):",
        "detail": "src.hallucination_llm_evaluation.hallucination_benchmark",
        "documentation": {}
    },
    {
        "label": "DataHandler",
        "kind": 6,
        "importPath": "src.med_llm_evaluation.data_handler",
        "description": "src.med_llm_evaluation.data_handler",
        "peekOfCode": "class DataHandler:\n    \"\"\"Handles loading and preprocessing of medical evaluation data.\"\"\"\n    def __init__(self, cache_dir: str = \".cache/med_eval\"):\n        \"\"\"\n        Initialize DataHandler with cache directory.\n        Args:\n            cache_dir (str): Directory for caching downloaded data\n        \"\"\"\n        self.cache_dir = Path(cache_dir)\n        self.cache_dir.mkdir(parents=True, exist_ok=True)",
        "detail": "src.med_llm_evaluation.data_handler",
        "documentation": {}
    },
    {
        "label": "logger",
        "kind": 5,
        "importPath": "src.med_llm_evaluation.data_handler",
        "description": "src.med_llm_evaluation.data_handler",
        "peekOfCode": "logger = logging.getLogger(__name__)\nclass DataHandler:\n    \"\"\"Handles loading and preprocessing of medical evaluation data.\"\"\"\n    def __init__(self, cache_dir: str = \".cache/med_eval\"):\n        \"\"\"\n        Initialize DataHandler with cache directory.\n        Args:\n            cache_dir (str): Directory for caching downloaded data\n        \"\"\"\n        self.cache_dir = Path(cache_dir)",
        "detail": "src.med_llm_evaluation.data_handler",
        "documentation": {}
    },
    {
        "label": "logger",
        "kind": 5,
        "importPath": "src.med_llm_evaluation.example",
        "description": "src.med_llm_evaluation.example",
        "peekOfCode": "logger = logging.getLogger(__name__)\n# Get API key from environment variable\napi_key = os.getenv('GOODFIRE_API_KEY')\nif not api_key:\n    raise ValueError(\"Please set the GOODFIRE_API_KEY environment variable\")\n# Initialize Goodfire client\nclient = goodfire.Client(api_key)\nvariant = goodfire.Variant(\"meta-llama/Meta-Llama-3-8B-Instruct\")\n# Initialize evaluator\nevaluator = MedicalLLMEvaluator(client, variant)",
        "detail": "src.med_llm_evaluation.example",
        "documentation": {}
    },
    {
        "label": "api_key",
        "kind": 5,
        "importPath": "src.med_llm_evaluation.example",
        "description": "src.med_llm_evaluation.example",
        "peekOfCode": "api_key = os.getenv('GOODFIRE_API_KEY')\nif not api_key:\n    raise ValueError(\"Please set the GOODFIRE_API_KEY environment variable\")\n# Initialize Goodfire client\nclient = goodfire.Client(api_key)\nvariant = goodfire.Variant(\"meta-llama/Meta-Llama-3-8B-Instruct\")\n# Initialize evaluator\nevaluator = MedicalLLMEvaluator(client, variant)\n# Run evaluation\naccuracy, kappa, results, stats = evaluator.run_evaluation(",
        "detail": "src.med_llm_evaluation.example",
        "documentation": {}
    },
    {
        "label": "client",
        "kind": 5,
        "importPath": "src.med_llm_evaluation.example",
        "description": "src.med_llm_evaluation.example",
        "peekOfCode": "client = goodfire.Client(api_key)\nvariant = goodfire.Variant(\"meta-llama/Meta-Llama-3-8B-Instruct\")\n# Initialize evaluator\nevaluator = MedicalLLMEvaluator(client, variant)\n# Run evaluation\naccuracy, kappa, results, stats = evaluator.run_evaluation(\n    k=30,              # number of samples\n    random_seed=42,    # for reproducibility\n    max_workers=10,    # concurrent API calls\n    subject_name=None  # optionally filter by subject",
        "detail": "src.med_llm_evaluation.example",
        "documentation": {}
    },
    {
        "label": "variant",
        "kind": 5,
        "importPath": "src.med_llm_evaluation.example",
        "description": "src.med_llm_evaluation.example",
        "peekOfCode": "variant = goodfire.Variant(\"meta-llama/Meta-Llama-3-8B-Instruct\")\n# Initialize evaluator\nevaluator = MedicalLLMEvaluator(client, variant)\n# Run evaluation\naccuracy, kappa, results, stats = evaluator.run_evaluation(\n    k=30,              # number of samples\n    random_seed=42,    # for reproducibility\n    max_workers=10,    # concurrent API calls\n    subject_name=None  # optionally filter by subject\n)",
        "detail": "src.med_llm_evaluation.example",
        "documentation": {}
    },
    {
        "label": "evaluator",
        "kind": 5,
        "importPath": "src.med_llm_evaluation.example",
        "description": "src.med_llm_evaluation.example",
        "peekOfCode": "evaluator = MedicalLLMEvaluator(client, variant)\n# Run evaluation\naccuracy, kappa, results, stats = evaluator.run_evaluation(\n    k=30,              # number of samples\n    random_seed=42,    # for reproducibility\n    max_workers=10,    # concurrent API calls\n    subject_name=None  # optionally filter by subject\n)\n# Results are already logged by the evaluator\n# You can also access them programmatically:",
        "detail": "src.med_llm_evaluation.example",
        "documentation": {}
    },
    {
        "label": "AsyncLLMEvaluator",
        "kind": 6,
        "importPath": "src.med_llm_evaluation.llm_evaluator",
        "description": "src.med_llm_evaluation.llm_evaluator",
        "peekOfCode": "class AsyncLLMEvaluator:\n    \"\"\"Handles async evaluation of LLM performance on medical questions.\"\"\"\n    def __init__(self, client, variant, batch_size: int = 10):\n        \"\"\"\n        Initialize evaluator with API client and variant.\n        Args:\n            client: The async API client instance\n            variant: The model variant to use\n            batch_size: Number of concurrent requests to process\n        \"\"\"",
        "detail": "src.med_llm_evaluation.llm_evaluator",
        "documentation": {}
    },
    {
        "label": "logger",
        "kind": 5,
        "importPath": "src.med_llm_evaluation.llm_evaluator",
        "description": "src.med_llm_evaluation.llm_evaluator",
        "peekOfCode": "logger = logging.getLogger(__name__)\nclass AsyncLLMEvaluator:\n    \"\"\"Handles async evaluation of LLM performance on medical questions.\"\"\"\n    def __init__(self, client, variant, batch_size: int = 10):\n        \"\"\"\n        Initialize evaluator with API client and variant.\n        Args:\n            client: The async API client instance\n            variant: The model variant to use\n            batch_size: Number of concurrent requests to process",
        "detail": "src.med_llm_evaluation.llm_evaluator",
        "documentation": {}
    },
    {
        "label": "AsyncMedicalLLMEvaluator",
        "kind": 6,
        "importPath": "src.med_llm_evaluation.medical_evaluator",
        "description": "src.med_llm_evaluation.medical_evaluator",
        "peekOfCode": "class AsyncMedicalLLMEvaluator:\n    \"\"\"Main interface for evaluating LLM performance on medical questions.\"\"\"\n    def __init__(self, client, variant, batch_size: int = 10, cache_dir: str = \".cache/med_eval\"):\n        \"\"\"\n        Initialize the medical LLM evaluator.\n        Args:\n            client: The API client instance\n            variant: The model variant to use\n            batch_size (int): Number of concurrent requests to process\n            cache_dir (str): Directory for caching downloaded data",
        "detail": "src.med_llm_evaluation.medical_evaluator",
        "documentation": {}
    },
    {
        "label": "logger",
        "kind": 5,
        "importPath": "src.med_llm_evaluation.medical_evaluator",
        "description": "src.med_llm_evaluation.medical_evaluator",
        "peekOfCode": "logger = logging.getLogger(__name__)\nclass AsyncMedicalLLMEvaluator:\n    \"\"\"Main interface for evaluating LLM performance on medical questions.\"\"\"\n    def __init__(self, client, variant, batch_size: int = 10, cache_dir: str = \".cache/med_eval\"):\n        \"\"\"\n        Initialize the medical LLM evaluator.\n        Args:\n            client: The API client instance\n            variant: The model variant to use\n            batch_size (int): Number of concurrent requests to process",
        "detail": "src.med_llm_evaluation.medical_evaluator",
        "documentation": {}
    },
    {
        "label": "StatisticalAnalyzer",
        "kind": 6,
        "importPath": "src.med_llm_evaluation.statistical_analyzer",
        "description": "src.med_llm_evaluation.statistical_analyzer",
        "peekOfCode": "class StatisticalAnalyzer:\n    \"\"\"Handles statistical analysis of model performance.\"\"\"\n    @staticmethod\n    def analyze(y_true: List[int], \n                y_pred: List[int], \n                alpha: float = 0.05) -> Dict:\n        \"\"\"\n        Analyze if model performance is significantly better than random.\n        Args:\n            y_true (List[int]): True labels",
        "detail": "src.med_llm_evaluation.statistical_analyzer",
        "documentation": {}
    },
    {
        "label": "logger",
        "kind": 5,
        "importPath": "src.med_llm_evaluation.utils",
        "description": "src.med_llm_evaluation.utils",
        "peekOfCode": "logger = logging.getLogger(__name__)",
        "detail": "src.med_llm_evaluation.utils",
        "documentation": {}
    },
    {
        "label": "split_prompt",
        "kind": 2,
        "importPath": "src.utils.utilities",
        "description": "src.utils.utilities",
        "peekOfCode": "def split_prompt(prompts):\n  system_prompt = ''\n  user_prompts = [] \n  for prompt in prompts:\n    split_index = prompt.find('[0,1,2,3].') + len('[0,1,2,3].')\n    system_prompt = prompt[:split_index].strip()\n    user_prompt = prompt[split_index:].strip()\n    user_prompts.append(user_prompt)\n  return system_prompt, user_prompts\nmock_responses = {",
        "detail": "src.utils.utilities",
        "documentation": {}
    },
    {
        "label": "mock_responses",
        "kind": 5,
        "importPath": "src.utils.utilities",
        "description": "src.utils.utilities",
        "peekOfCode": "mock_responses = {\n    \"What are the symptoms of diabetes?\": \"The common symptoms of diabetes include increased thirst, frequent urination, extreme fatigue, and blurry vision.\",\n    \"How to treat high blood pressure?\": \"High blood pressure can be managed with lifestyle changes such as reducing salt intake, regular exercise, and medications like ACE inhibitors.\",\n    \"What are common causes of fatigue?\": \"Common causes of fatigue include stress, poor sleep quality, anemia, and chronic medical conditions like hypothyroidism.\"\n}\nactivated_features = [\"Feature A\", \"Feature B\", \"Feature C\"]",
        "detail": "src.utils.utilities",
        "documentation": {}
    },
    {
        "label": "activated_features",
        "kind": 5,
        "importPath": "src.utils.utilities",
        "description": "src.utils.utilities",
        "peekOfCode": "activated_features = [\"Feature A\", \"Feature B\", \"Feature C\"]",
        "detail": "src.utils.utilities",
        "documentation": {}
    },
    {
        "label": "logger",
        "kind": 5,
        "importPath": "src.app",
        "description": "src.app",
        "peekOfCode": "logger = logging.getLogger(__name__)\nrender_navbar()\nst.title(\"Diagnostics Page\")\nst.markdown(\"Refine model outputs using feature steering and analyze response quality.\")\nst.markdown(\"---\")\nst.header(\"Model Inference\")\ndata_handler = DataHandler()\nprompts, labels, subject_names = data_handler.load_data()\nprompts_with_labels = dict(zip(prompts, labels))\nsystem_prompt, user_prompts = split_prompt(prompts[:10])",
        "detail": "src.app",
        "documentation": {}
    },
    {
        "label": "data_handler",
        "kind": 5,
        "importPath": "src.app",
        "description": "src.app",
        "peekOfCode": "data_handler = DataHandler()\nprompts, labels, subject_names = data_handler.load_data()\nprompts_with_labels = dict(zip(prompts, labels))\nsystem_prompt, user_prompts = split_prompt(prompts[:10])\ncols = st.columns([3, 1])  \nwith cols[0]:\n    selected_prompt = st.selectbox(\"Select a predefined question:\", user_prompts)\n    selected_user_prompt = system_prompt + \"\\n\\n\" + selected_prompt\n    ground_truth_label = prompts_with_labels[selected_user_prompt]\n    if st.button(\"Submit Query\"):",
        "detail": "src.app",
        "documentation": {}
    },
    {
        "label": "prompts_with_labels",
        "kind": 5,
        "importPath": "src.app",
        "description": "src.app",
        "peekOfCode": "prompts_with_labels = dict(zip(prompts, labels))\nsystem_prompt, user_prompts = split_prompt(prompts[:10])\ncols = st.columns([3, 1])  \nwith cols[0]:\n    selected_prompt = st.selectbox(\"Select a predefined question:\", user_prompts)\n    selected_user_prompt = system_prompt + \"\\n\\n\" + selected_prompt\n    ground_truth_label = prompts_with_labels[selected_user_prompt]\n    if st.button(\"Submit Query\"):\n        response_text = \"\"\n        try: ",
        "detail": "src.app",
        "documentation": {}
    },
    {
        "label": "cols",
        "kind": 5,
        "importPath": "src.app",
        "description": "src.app",
        "peekOfCode": "cols = st.columns([3, 1])  \nwith cols[0]:\n    selected_prompt = st.selectbox(\"Select a predefined question:\", user_prompts)\n    selected_user_prompt = system_prompt + \"\\n\\n\" + selected_prompt\n    ground_truth_label = prompts_with_labels[selected_user_prompt]\n    if st.button(\"Submit Query\"):\n        response_text = \"\"\n        try: \n           response = client.chat.completions.create(\n             messages=[{\"role\": 'user', \"content\": selected_user_prompt}],",
        "detail": "src.app",
        "documentation": {}
    }
]