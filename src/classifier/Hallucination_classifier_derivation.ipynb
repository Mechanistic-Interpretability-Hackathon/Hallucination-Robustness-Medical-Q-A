{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ast\n",
    "import json\n",
    "from typing import Optional, Tuple\n",
    "\n",
    "def get_balanced_samples(df: pd.DataFrame, \n",
    "                        n_per_class: Optional[int] = None,\n",
    "                        train_fraction: float = 0.8,\n",
    "                        random_state: Optional[int] = None) -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Randomly sample an equal number of records where hallucinated is True and False,\n",
    "    split into training and test sets, and format prompts for each row.\n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame): Input DataFrame with 'hallucinated', 'question', and 'options' columns\n",
    "        n_per_class (int, optional): Number of samples to take from each class.\n",
    "                                   If None, uses the size of the smaller class.\n",
    "        train_fraction (float): Fraction of data to use for training (default: 0.8)\n",
    "        random_state (int, optional): Random seed for reproducibility\n",
    "    \n",
    "    Returns:\n",
    "        Tuple[pd.DataFrame, pd.DataFrame]: (train_df, test_df) containing balanced samples\n",
    "                                         with formatted prompts\n",
    "    \"\"\"\n",
    "    if not 0 < train_fraction < 1:\n",
    "        raise ValueError(\"train_fraction must be between 0 and 1\")\n",
    "    \n",
    "    # Ensure hallucinated column is boolean\n",
    "    df = df.copy()\n",
    "\n",
    "    # Filter by activation if the column exists\n",
    "    if 'activation' in df.columns:\n",
    "        original_len = len(df)\n",
    "        df = df[df['activation'] == 0]\n",
    "        filtered_len = len(df)\n",
    "\n",
    "        if filtered_len == 0:\n",
    "            raise ValueError(\"No rows remaining after filtering activation = 0\")\n",
    "\n",
    "    # Ensure hallucinated column is boolean\n",
    "    df['hallucinated'] = df['hallucinated'].astype(bool)\n",
    "    \n",
    "    # Split into True and False groups\n",
    "    true_samples = df[df['hallucinated'] == True]\n",
    "    false_samples = df[df['hallucinated'] == False]\n",
    "    \n",
    "    # Get counts\n",
    "    n_true = len(true_samples)\n",
    "    n_false = len(false_samples)\n",
    "    \n",
    "    # If n_per_class not specified, use size of smaller group\n",
    "    if n_per_class is None:\n",
    "        n_per_class = min(n_true, n_false)\n",
    "    \n",
    "    # Verify we have enough samples\n",
    "    if n_per_class > min(n_true, n_false):\n",
    "        raise ValueError(f\"Requested {n_per_class} samples per class but smallest class only has {min(n_true, n_false)} samples\")\n",
    "    \n",
    "    # Sample from each group\n",
    "    sampled_true = true_samples.sample(n=n_per_class, random_state=random_state)\n",
    "    sampled_false = false_samples.sample(n=n_per_class, random_state=random_state)\n",
    "    \n",
    "    # Calculate number of training samples (ensuring even split between classes)\n",
    "    n_train_per_class = int(n_per_class * train_fraction)\n",
    "    \n",
    "    # Split each class into train and test\n",
    "    train_true = sampled_true.iloc[:n_train_per_class]\n",
    "    test_true = sampled_true.iloc[n_train_per_class:]\n",
    "    \n",
    "    train_false = sampled_false.iloc[:n_train_per_class]\n",
    "    test_false = sampled_false.iloc[n_train_per_class:]\n",
    "    \n",
    "    # Combine and shuffle train and test sets\n",
    "    train_df = pd.concat([train_true, train_false])\n",
    "    train_df = train_df.sample(frac=1, random_state=random_state).reset_index(drop=True)\n",
    "    \n",
    "    test_df = pd.concat([test_true, test_false])\n",
    "    test_df = test_df.sample(frac=1, random_state=random_state).reset_index(drop=True)\n",
    "    \n",
    "    # Format prompts for both datasets\n",
    "    def format_prompts(df):\n",
    "        introduction = (\"You are a medical expert and this is a multiple choice exam question. \"\n",
    "                       \"Please respond with the integer index of the CORRECT answer only; [0,1,2,3].\")\n",
    "        \n",
    "        formatted_df = df.copy()\n",
    "        formatted_prompts = []\n",
    "        \n",
    "        for _, row in df.iterrows():\n",
    "            question = row['question']\n",
    "            \n",
    "            # Parse options\n",
    "            if isinstance(row['options'], str):\n",
    "                options_dict = ast.literal_eval(row['options'])\n",
    "            elif isinstance(row['options'], list) and len(row['options']) > 0:\n",
    "                options_dict = row['options'][0]\n",
    "            else:\n",
    "                options_dict = row['options']\n",
    "            \n",
    "            # Filter out 'correct answer' from options\n",
    "            options_filtered = {k: v for k, v in options_dict.items() if k != 'correct answer'}\n",
    "            options_formatted = \"Options: \" + json.dumps(options_filtered)\n",
    "            \n",
    "            # Construct prompt\n",
    "            prompt = f\"{introduction}\\n\\n{question}\\n\\n{options_formatted}\"\n",
    "            formatted_prompts.append(prompt)\n",
    "        \n",
    "        formatted_df['prompt'] = formatted_prompts\n",
    "        return formatted_df\n",
    "    \n",
    "    # Apply prompt formatting to both datasets\n",
    "    train_df = format_prompts(train_df)\n",
    "    test_df = format_prompts(test_df)\n",
    "    \n",
    "    print(f\"Created balanced samples with {n_per_class} records per class\")\n",
    "    print(f\"Training set: {len(train_df)} records ({n_train_per_class} per class)\")\n",
    "    print(f\"Test set: {len(test_df)} records ({n_per_class - n_train_per_class} per class)\")\n",
    "    print(\"\\nClass distribution in training set:\")\n",
    "    print(train_df['hallucinated'].value_counts())\n",
    "    print(\"\\nClass distribution in test set:\")\n",
    "    print(test_df['hallucinated'].value_counts())\n",
    "    \n",
    "    return train_df, test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created balanced samples with 125 records per class\n",
      "Training set: 200 records (100 per class)\n",
      "Test set: 50 records (25 per class)\n",
      "\n",
      "Class distribution in training set:\n",
      "hallucinated\n",
      "True     100\n",
      "False    100\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Class distribution in test set:\n",
      "hallucinated\n",
      "True     25\n",
      "False    25\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "file_path = '../data/fct_responses_clean.tsv'\n",
    "\n",
    "# Read the TSV file\n",
    "df = pd.read_csv(file_path, sep='\\t')\n",
    "\n",
    "# Get balanced samples with train/test split\n",
    "train_data, test_data = get_balanced_samples(\n",
    "    df=df,\n",
    "    n_per_class=125,\n",
    "    train_fraction=0.8,\n",
    "    random_state=42\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import goodfire\n",
    "import os\n",
    "\n",
    "api_key ='sk-goodfire-9IJgLomji2zNdvFLPsTYPQvPPr_kUC19bFTh0HgT9h6SikyfPB7WmQ'\n",
    "client  = goodfire.Client(api_key)\n",
    "variant = goodfire.Variant(\"meta-llama/Meta-Llama-3-8B-Instruct\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ReadTimeout",
     "evalue": "The read operation timed out",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mReadTimeout\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[0;32m~/Documents/Projects/A.I./Prototype/Mech Interp/.venv/lib/python3.11/site-packages/httpx/_transports/default.py:72\u001b[0m, in \u001b[0;36mmap_httpcore_exceptions\u001b[0;34m()\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 72\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "File \u001b[0;32m~/Documents/Projects/A.I./Prototype/Mech Interp/.venv/lib/python3.11/site-packages/httpx/_transports/default.py:236\u001b[0m, in \u001b[0;36mHTTPTransport.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    235\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[0;32m--> 236\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_pool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    238\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(resp\u001b[38;5;241m.\u001b[39mstream, typing\u001b[38;5;241m.\u001b[39mIterable)\n",
      "File \u001b[0;32m~/Documents/Projects/A.I./Prototype/Mech Interp/.venv/lib/python3.11/site-packages/httpcore/_sync/connection_pool.py:256\u001b[0m, in \u001b[0;36mConnectionPool.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    255\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_close_connections(closing)\n\u001b[0;32m--> 256\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    258\u001b[0m \u001b[38;5;66;03m# Return the response. Note that in this case we still have to manage\u001b[39;00m\n\u001b[1;32m    259\u001b[0m \u001b[38;5;66;03m# the point at which the response is closed.\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/Projects/A.I./Prototype/Mech Interp/.venv/lib/python3.11/site-packages/httpcore/_sync/connection_pool.py:236\u001b[0m, in \u001b[0;36mConnectionPool.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    234\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    235\u001b[0m     \u001b[38;5;66;03m# Send the request on the assigned connection.\u001b[39;00m\n\u001b[0;32m--> 236\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    237\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpool_request\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\n\u001b[1;32m    238\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    239\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ConnectionNotAvailable:\n\u001b[1;32m    240\u001b[0m     \u001b[38;5;66;03m# In some cases a connection may initially be available to\u001b[39;00m\n\u001b[1;32m    241\u001b[0m     \u001b[38;5;66;03m# handle a request, but then become unavailable.\u001b[39;00m\n\u001b[1;32m    242\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m    243\u001b[0m     \u001b[38;5;66;03m# In this case we clear the connection and try again.\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/Projects/A.I./Prototype/Mech Interp/.venv/lib/python3.11/site-packages/httpcore/_sync/connection.py:103\u001b[0m, in \u001b[0;36mHTTPConnection.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    101\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc\n\u001b[0;32m--> 103\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_connection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Projects/A.I./Prototype/Mech Interp/.venv/lib/python3.11/site-packages/httpcore/_sync/http11.py:136\u001b[0m, in \u001b[0;36mHTTP11Connection.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    135\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_response_closed()\n\u001b[0;32m--> 136\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exc\n",
      "File \u001b[0;32m~/Documents/Projects/A.I./Prototype/Mech Interp/.venv/lib/python3.11/site-packages/httpcore/_sync/http11.py:106\u001b[0m, in \u001b[0;36mHTTP11Connection.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m Trace(\n\u001b[1;32m     98\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreceive_response_headers\u001b[39m\u001b[38;5;124m\"\u001b[39m, logger, request, kwargs\n\u001b[1;32m     99\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[1;32m    100\u001b[0m     (\n\u001b[1;32m    101\u001b[0m         http_version,\n\u001b[1;32m    102\u001b[0m         status,\n\u001b[1;32m    103\u001b[0m         reason_phrase,\n\u001b[1;32m    104\u001b[0m         headers,\n\u001b[1;32m    105\u001b[0m         trailing_data,\n\u001b[0;32m--> 106\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_receive_response_headers\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    107\u001b[0m     trace\u001b[38;5;241m.\u001b[39mreturn_value \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    108\u001b[0m         http_version,\n\u001b[1;32m    109\u001b[0m         status,\n\u001b[1;32m    110\u001b[0m         reason_phrase,\n\u001b[1;32m    111\u001b[0m         headers,\n\u001b[1;32m    112\u001b[0m     )\n",
      "File \u001b[0;32m~/Documents/Projects/A.I./Prototype/Mech Interp/.venv/lib/python3.11/site-packages/httpcore/_sync/http11.py:177\u001b[0m, in \u001b[0;36mHTTP11Connection._receive_response_headers\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    176\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 177\u001b[0m     event \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_receive_event\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    178\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(event, h11\u001b[38;5;241m.\u001b[39mResponse):\n",
      "File \u001b[0;32m~/Documents/Projects/A.I./Prototype/Mech Interp/.venv/lib/python3.11/site-packages/httpcore/_sync/http11.py:217\u001b[0m, in \u001b[0;36mHTTP11Connection._receive_event\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    216\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m event \u001b[38;5;129;01mis\u001b[39;00m h11\u001b[38;5;241m.\u001b[39mNEED_DATA:\n\u001b[0;32m--> 217\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_network_stream\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    218\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mREAD_NUM_BYTES\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[1;32m    219\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    221\u001b[0m     \u001b[38;5;66;03m# If we feed this case through h11 we'll raise an exception like:\u001b[39;00m\n\u001b[1;32m    222\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m    223\u001b[0m     \u001b[38;5;66;03m#     httpcore.RemoteProtocolError: can't handle event type\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[38;5;66;03m# perspective. Instead we handle this case distinctly and treat\u001b[39;00m\n\u001b[1;32m    228\u001b[0m     \u001b[38;5;66;03m# it as a ConnectError.\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/Projects/A.I./Prototype/Mech Interp/.venv/lib/python3.11/site-packages/httpcore/_backends/sync.py:126\u001b[0m, in \u001b[0;36mSyncStream.read\u001b[0;34m(self, max_bytes, timeout)\u001b[0m\n\u001b[1;32m    125\u001b[0m exc_map: ExceptionMapping \u001b[38;5;241m=\u001b[39m {socket\u001b[38;5;241m.\u001b[39mtimeout: ReadTimeout, \u001b[38;5;167;01mOSError\u001b[39;00m: ReadError}\n\u001b[0;32m--> 126\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmap_exceptions\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexc_map\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m    127\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msettimeout\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/contextlib.py:155\u001b[0m, in \u001b[0;36m_GeneratorContextManager.__exit__\u001b[0;34m(self, typ, value, traceback)\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 155\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgen\u001b[38;5;241m.\u001b[39mthrow(typ, value, traceback)\n\u001b[1;32m    156\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m    157\u001b[0m     \u001b[38;5;66;03m# Suppress StopIteration *unless* it's the same exception that\u001b[39;00m\n\u001b[1;32m    158\u001b[0m     \u001b[38;5;66;03m# was passed to throw().  This prevents a StopIteration\u001b[39;00m\n\u001b[1;32m    159\u001b[0m     \u001b[38;5;66;03m# raised inside the \"with\" statement from being suppressed.\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/Projects/A.I./Prototype/Mech Interp/.venv/lib/python3.11/site-packages/httpcore/_exceptions.py:14\u001b[0m, in \u001b[0;36mmap_exceptions\u001b[0;34m(map)\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(exc, from_exc):\n\u001b[0;32m---> 14\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m to_exc(exc) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexc\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[0;31mReadTimeout\u001b[0m: The read operation timed out",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mReadTimeout\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 18\u001b[0m\n\u001b[1;32m      4\u001b[0m dataset_1 \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m      5\u001b[0m     [\n\u001b[1;32m      6\u001b[0m         {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: prompt},\n\u001b[1;32m      7\u001b[0m         {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124massistant\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m3\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n\u001b[1;32m      8\u001b[0m     ] \u001b[38;5;28;01mfor\u001b[39;00m prompt \u001b[38;5;129;01min\u001b[39;00m hallucinated_examples[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprompt\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[1;32m      9\u001b[0m ]\n\u001b[1;32m     11\u001b[0m dataset_2 \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     12\u001b[0m     [\n\u001b[1;32m     13\u001b[0m         {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: prompt},\n\u001b[1;32m     14\u001b[0m         {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124massistant\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m3\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n\u001b[1;32m     15\u001b[0m     ] \u001b[38;5;28;01mfor\u001b[39;00m prompt \u001b[38;5;129;01min\u001b[39;00m truthful_examples[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprompt\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[1;32m     16\u001b[0m ]\n\u001b[0;32m---> 18\u001b[0m hallucinated_features, truthful_features \u001b[38;5;241m=\u001b[39m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeatures\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontrast\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdataset_1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdataset_1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdataset_2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdataset_2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdataset_1_feature_rerank_query\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmedical response hallucinated\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdataset_2_feature_rerank_query\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmedical response truthful\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvariant\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtop_k\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\n\u001b[1;32m     25\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m features_to_look_at \u001b[38;5;241m=\u001b[39m hallucinated_features \u001b[38;5;241m|\u001b[39m truthful_features\n\u001b[1;32m     27\u001b[0m features_to_look_at\n",
      "File \u001b[0;32m~/Documents/Projects/A.I./Prototype/Mech Interp/.venv/lib/python3.11/site-packages/goodfire/api/features/client.py:274\u001b[0m, in \u001b[0;36mFeaturesAPI.contrast\u001b[0;34m(self, dataset_1, dataset_2, model, dataset_1_feature_rerank_query, dataset_2_feature_rerank_query, top_k)\u001b[0m\n\u001b[1;32m    265\u001b[0m payload \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    266\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdataset_1\u001b[39m\u001b[38;5;124m\"\u001b[39m: dataset_1,\n\u001b[1;32m    267\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdataset_2\u001b[39m\u001b[38;5;124m\"\u001b[39m: dataset_2,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    270\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m: model \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(model, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m model\u001b[38;5;241m.\u001b[39mbase_model,\n\u001b[1;32m    271\u001b[0m }\n\u001b[1;32m    273\u001b[0m headers \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_headers()\n\u001b[0;32m--> 274\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_http\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpost\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjson\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpayload\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    276\u001b[0m response_body \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mjson()\n\u001b[1;32m    278\u001b[0m dataset_1_features \u001b[38;5;241m=\u001b[39m FeatureGroup(\n\u001b[1;32m    279\u001b[0m     [\n\u001b[1;32m    280\u001b[0m         Feature(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    287\u001b[0m     ]\n\u001b[1;32m    288\u001b[0m )\n",
      "File \u001b[0;32m~/Documents/Projects/A.I./Prototype/Mech Interp/.venv/lib/python3.11/site-packages/goodfire/api/utils.py:51\u001b[0m, in \u001b[0;36mHTTPWrapper.post\u001b[0;34m(self, url, headers, json, _attempt_num, timeout)\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(\n\u001b[1;32m     43\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m     44\u001b[0m     url: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     48\u001b[0m     timeout: Optional[\u001b[38;5;28mint\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m,\n\u001b[1;32m     49\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m httpx\u001b[38;5;241m.\u001b[39mResponse:\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m httpx\u001b[38;5;241m.\u001b[39mClient() \u001b[38;5;28;01mas\u001b[39;00m client:\n\u001b[0;32m---> 51\u001b[0m         response \u001b[38;5;241m=\u001b[39m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpost\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjson\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjson\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     52\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m             check_status_code(response\u001b[38;5;241m.\u001b[39mstatus_code, response\u001b[38;5;241m.\u001b[39mtext)\n",
      "File \u001b[0;32m~/Documents/Projects/A.I./Prototype/Mech Interp/.venv/lib/python3.11/site-packages/httpx/_client.py:1157\u001b[0m, in \u001b[0;36mClient.post\u001b[0;34m(self, url, content, data, files, json, params, headers, cookies, auth, follow_redirects, timeout, extensions)\u001b[0m\n\u001b[1;32m   1136\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(\n\u001b[1;32m   1137\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1138\u001b[0m     url: URL \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1150\u001b[0m     extensions: RequestExtensions \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1151\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Response:\n\u001b[1;32m   1152\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1153\u001b[0m \u001b[38;5;124;03m    Send a `POST` request.\u001b[39;00m\n\u001b[1;32m   1154\u001b[0m \n\u001b[1;32m   1155\u001b[0m \u001b[38;5;124;03m    **Parameters**: See `httpx.request`.\u001b[39;00m\n\u001b[1;32m   1156\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1157\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1158\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mPOST\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1159\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1160\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcontent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcontent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1161\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1162\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfiles\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfiles\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1163\u001b[0m \u001b[43m        \u001b[49m\u001b[43mjson\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjson\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1164\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1165\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1166\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcookies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcookies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1167\u001b[0m \u001b[43m        \u001b[49m\u001b[43mauth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mauth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1168\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1169\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1170\u001b[0m \u001b[43m        \u001b[49m\u001b[43mextensions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextensions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1171\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Projects/A.I./Prototype/Mech Interp/.venv/lib/python3.11/site-packages/httpx/_client.py:837\u001b[0m, in \u001b[0;36mClient.request\u001b[0;34m(self, method, url, content, data, files, json, params, headers, cookies, auth, follow_redirects, timeout, extensions)\u001b[0m\n\u001b[1;32m    822\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(message, \u001b[38;5;167;01mDeprecationWarning\u001b[39;00m)\n\u001b[1;32m    824\u001b[0m request \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuild_request(\n\u001b[1;32m    825\u001b[0m     method\u001b[38;5;241m=\u001b[39mmethod,\n\u001b[1;32m    826\u001b[0m     url\u001b[38;5;241m=\u001b[39murl,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    835\u001b[0m     extensions\u001b[38;5;241m=\u001b[39mextensions,\n\u001b[1;32m    836\u001b[0m )\n\u001b[0;32m--> 837\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mauth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mauth\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Projects/A.I./Prototype/Mech Interp/.venv/lib/python3.11/site-packages/httpx/_client.py:926\u001b[0m, in \u001b[0;36mClient.send\u001b[0;34m(self, request, stream, auth, follow_redirects)\u001b[0m\n\u001b[1;32m    922\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_timeout(request)\n\u001b[1;32m    924\u001b[0m auth \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_request_auth(request, auth)\n\u001b[0;32m--> 926\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_handling_auth\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    927\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    928\u001b[0m \u001b[43m    \u001b[49m\u001b[43mauth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mauth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    929\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    930\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhistory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    931\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    932\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    933\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stream:\n",
      "File \u001b[0;32m~/Documents/Projects/A.I./Prototype/Mech Interp/.venv/lib/python3.11/site-packages/httpx/_client.py:954\u001b[0m, in \u001b[0;36mClient._send_handling_auth\u001b[0;34m(self, request, auth, follow_redirects, history)\u001b[0m\n\u001b[1;32m    951\u001b[0m request \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(auth_flow)\n\u001b[1;32m    953\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 954\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_handling_redirects\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    955\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    956\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    957\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhistory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhistory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    958\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    959\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    960\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/Documents/Projects/A.I./Prototype/Mech Interp/.venv/lib/python3.11/site-packages/httpx/_client.py:991\u001b[0m, in \u001b[0;36mClient._send_handling_redirects\u001b[0;34m(self, request, follow_redirects, history)\u001b[0m\n\u001b[1;32m    988\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_event_hooks[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequest\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m    989\u001b[0m     hook(request)\n\u001b[0;32m--> 991\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_single_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    992\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    993\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_event_hooks[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n",
      "File \u001b[0;32m~/Documents/Projects/A.I./Prototype/Mech Interp/.venv/lib/python3.11/site-packages/httpx/_client.py:1027\u001b[0m, in \u001b[0;36mClient._send_single_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m   1023\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAttempted to send an async request with a sync Client instance.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1024\u001b[0m     )\n\u001b[1;32m   1026\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m request_context(request\u001b[38;5;241m=\u001b[39mrequest):\n\u001b[0;32m-> 1027\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mtransport\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1029\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response\u001b[38;5;241m.\u001b[39mstream, SyncByteStream)\n\u001b[1;32m   1031\u001b[0m response\u001b[38;5;241m.\u001b[39mrequest \u001b[38;5;241m=\u001b[39m request\n",
      "File \u001b[0;32m~/Documents/Projects/A.I./Prototype/Mech Interp/.venv/lib/python3.11/site-packages/httpx/_transports/default.py:235\u001b[0m, in \u001b[0;36mHTTPTransport.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    221\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(request\u001b[38;5;241m.\u001b[39mstream, SyncByteStream)\n\u001b[1;32m    223\u001b[0m req \u001b[38;5;241m=\u001b[39m httpcore\u001b[38;5;241m.\u001b[39mRequest(\n\u001b[1;32m    224\u001b[0m     method\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mmethod,\n\u001b[1;32m    225\u001b[0m     url\u001b[38;5;241m=\u001b[39mhttpcore\u001b[38;5;241m.\u001b[39mURL(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    233\u001b[0m     extensions\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mextensions,\n\u001b[1;32m    234\u001b[0m )\n\u001b[0;32m--> 235\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmap_httpcore_exceptions\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m    236\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresp\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_pool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    238\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(resp\u001b[38;5;241m.\u001b[39mstream, typing\u001b[38;5;241m.\u001b[39mIterable)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/contextlib.py:155\u001b[0m, in \u001b[0;36m_GeneratorContextManager.__exit__\u001b[0;34m(self, typ, value, traceback)\u001b[0m\n\u001b[1;32m    153\u001b[0m     value \u001b[38;5;241m=\u001b[39m typ()\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 155\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgen\u001b[38;5;241m.\u001b[39mthrow(typ, value, traceback)\n\u001b[1;32m    156\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m    157\u001b[0m     \u001b[38;5;66;03m# Suppress StopIteration *unless* it's the same exception that\u001b[39;00m\n\u001b[1;32m    158\u001b[0m     \u001b[38;5;66;03m# was passed to throw().  This prevents a StopIteration\u001b[39;00m\n\u001b[1;32m    159\u001b[0m     \u001b[38;5;66;03m# raised inside the \"with\" statement from being suppressed.\u001b[39;00m\n\u001b[1;32m    160\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m exc \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m value\n",
      "File \u001b[0;32m~/Documents/Projects/A.I./Prototype/Mech Interp/.venv/lib/python3.11/site-packages/httpx/_transports/default.py:89\u001b[0m, in \u001b[0;36mmap_httpcore_exceptions\u001b[0;34m()\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[1;32m     88\u001b[0m message \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(exc)\n\u001b[0;32m---> 89\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m mapped_exc(message) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexc\u001b[39;00m\n",
      "\u001b[0;31mReadTimeout\u001b[0m: The read operation timed out"
     ]
    }
   ],
   "source": [
    "hallucinated_examples = train_data[train_data['hallucinated'] == True]\n",
    "truthful_examples     = train_data[train_data['hallucinated'] == False]\n",
    "\n",
    "dataset_1 = [\n",
    "    [\n",
    "        {\"role\": \"user\", \"content\": prompt},\n",
    "        {\"role\": \"assistant\", \"content\": \"3\"}\n",
    "    ] for prompt in hallucinated_examples['prompt'].tolist()\n",
    "]\n",
    "\n",
    "dataset_2 = [\n",
    "    [\n",
    "        {\"role\": \"user\", \"content\": prompt},\n",
    "        {\"role\": \"assistant\", \"content\": \"3\"}\n",
    "    ] for prompt in truthful_examples['prompt'].tolist()\n",
    "]\n",
    "\n",
    "hallucinated_features, truthful_features = client.features.contrast(\n",
    "    dataset_1=dataset_1,\n",
    "    dataset_2=dataset_2,\n",
    "    dataset_1_feature_rerank_query=\"medical response hallucinated\",\n",
    "    dataset_2_feature_rerank_query=\"medical response truthful\",\n",
    "    model=variant,\n",
    "    top_k=50\n",
    ")\n",
    "features_to_look_at = hallucinated_features | truthful_features\n",
    "features_to_look_at"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "\n",
    "class FeatureMixer:\n",
    "  def __init__(self, feature_group):\n",
    "    self.feature_group = feature_group\n",
    "\n",
    "  def grid(self, k_features_per_combo: int =2):\n",
    "    \"\"\"Perform a grid search over all possible combinations of features\"\"\"\n",
    "\n",
    "    # Get all possible combinations of features\n",
    "    return list(combinations(self.feature_group, k_features_per_combo))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIN_SAMPLES_PER_CLASS: 100\n",
      "Computing hallucination medical features...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:35<00:00,  2.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing truthful medical features...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:35<00:00,  2.82it/s]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import concurrent.futures as futures\n",
    "import tqdm\n",
    "\n",
    "\n",
    "MIN_SAMPLES_PER_CLASS = min(\n",
    "    len(hallucinated_examples),\n",
    "    len(truthful_examples),\n",
    ")\n",
    "\n",
    "print(f\"MIN_SAMPLES_PER_CLASS: {MIN_SAMPLES_PER_CLASS}\")\n",
    "\n",
    "MAX_WORKERS = 3\n",
    "\n",
    "def _get_feature_acts_for_sample_class(\n",
    "    sample_class: pd.DataFrame,\n",
    "    features_to_use_for_classification: goodfire.FeatureGroup,\n",
    "    k=100,):\n",
    "\n",
    "    if k < len(features_to_use_for_classification):\n",
    "        raise ValueError(\"k must be greater than the number of features to use for classification\")\n",
    "\n",
    "    samples = []\n",
    "    with futures.ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:\n",
    "        futures_list = []\n",
    "        for idx, row in sample_class[0:MIN_SAMPLES_PER_CLASS].iterrows():\n",
    "            prompt = row['prompt']\n",
    "            futures_list.append(\n",
    "                executor.submit(\n",
    "                    client.features.inspect,\n",
    "                    [\n",
    "                        {\n",
    "                            \"role\": \"user\",\n",
    "                            \"content\": f\"{prompt}\"\n",
    "                        }\n",
    "                    ],\n",
    "                    model=variant,\n",
    "                    features=features_to_use_for_classification,\n",
    "                )\n",
    "            )\n",
    "\n",
    "        for future in tqdm.tqdm(futures_list):\n",
    "            context = future.result()\n",
    "\n",
    "            features = context.top(k=k)\n",
    "            samples.append(features)\n",
    "\n",
    "    return samples\n",
    "\n",
    "print(\"Computing hallucination medical features...\")\n",
    "positive_class_features = _get_feature_acts_for_sample_class(hallucinated_examples, features_to_look_at, k=100)\n",
    "\n",
    "print(\"Computing truthful medical features...\")\n",
    "negative_class_features = _get_feature_acts_for_sample_class(truthful_examples, features_to_look_at, k=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import balanced_accuracy_score, accuracy_score, f1_score\n",
    "import numpy as np\n",
    "import tqdm\n",
    "\n",
    "\n",
    "# Grid search may take a while, you can curate the feature list to speed this process up significantly\n",
    "\n",
    "def train_tree(x, y, depth):\n",
    "  train_x, test_x, train_y, test_y = train_test_split(x, y, train_size=0.5, random_state=42)\n",
    "\n",
    "  # Create a nice regularized tree\n",
    "  model = tree.DecisionTreeClassifier(\n",
    "    max_depth=depth,\n",
    "    min_samples_leaf=len(train_x) // 20,\n",
    "    random_state=42\n",
    "  )\n",
    "\n",
    "  model.fit(train_x, train_y)\n",
    "\n",
    "  pred = model.predict(test_x)\n",
    "\n",
    "  # Calculate the f1 score of the model\n",
    "  accuracy = balanced_accuracy_score(test_y, pred)\n",
    "  score = f1_score(test_y, pred)\n",
    "\n",
    "  return model, pred, score, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_combo(features, k_features_per_combo = 2):\n",
    "  combos = FeatureMixer(features).grid(k_features_per_combo=k_features_per_combo)\n",
    "  best_combo = None\n",
    "  best_model = None\n",
    "  mean_act_negative = 0\n",
    "  mean_act_positive = 0\n",
    "  support_vector_distances = 0\n",
    "  best_score = 0\n",
    "  best_accuracy = 0\n",
    "\n",
    "  MAX_WORKERS = 8\n",
    "\n",
    "  futures_list = []\n",
    "\n",
    "  with futures.ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:\n",
    "    for combo in combos:\n",
    "      def _test_combo(combo):\n",
    "        # Create a linear regression model\n",
    "        def _select_feature_acts(combo, row):\n",
    "          output = []\n",
    "          for index, feature in enumerate(combo):\n",
    "            for feature_act in row:\n",
    "              if feature_act.feature.uuid == feature.uuid:\n",
    "                output.append(feature_act.activation)\n",
    "                break\n",
    "\n",
    "          return output\n",
    "\n",
    "        x_negative = [_select_feature_acts(combo, row) for row in negative_class_features]\n",
    "        x_positive = [_select_feature_acts(combo, row) for row in positive_class_features]\n",
    "\n",
    "        y_negative = [-1] * len(x_negative)\n",
    "        y_positive = [1] * len(x_positive)\n",
    "\n",
    "        x = x_negative + x_positive\n",
    "        y = y_negative + y_positive\n",
    "\n",
    "        model, pred, score, accuracy = train_tree(x, y, depth=len(combo))\n",
    "\n",
    "        return model, pred, score, accuracy, combo\n",
    "\n",
    "      futures_list.append(executor.submit(_test_combo, combo))\n",
    "\n",
    "    for future in tqdm.tqdm(futures_list):\n",
    "      model, pred, score, accuracy, combo = future.result()\n",
    "\n",
    "      if score > best_score:\n",
    "        best_score = score\n",
    "        best_combo = combo\n",
    "        best_model = model\n",
    "        best_accuracy = accuracy\n",
    "\n",
    "  return best_combo, best_score, best_model, best_accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 53/53 [00:00<00:00, 94.18it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 (Feature(\"Proper nouns in media and entertainment contexts\"),) 0.6857142857142856 0.5682272909163666 DecisionTreeClassifier(max_depth=1, min_samples_leaf=5, random_state=42)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1378/1378 [00:22<00:00, 62.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 (Feature(\"The model should not recommend technological or medical interventions\"), Feature(\"Specialized academic or scientific terminology\")) 0.7107438016528925 0.6544617847138856 DecisionTreeClassifier(max_depth=2, min_samples_leaf=5, random_state=42)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23426/23426 [07:00<00:00, 55.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 (Feature(\"The model should not recommend technological or medical interventions\"), Feature(\"Specialized academic or scientific terminology\"), Feature(\"Proper nouns in media and entertainment contexts\")) 0.7304347826086957 0.6932773109243697 DecisionTreeClassifier(max_depth=3, min_samples_leaf=5, random_state=42)\n"
     ]
    }
   ],
   "source": [
    "best_combo_at_k = {}\n",
    "\n",
    "for i in range(3):\n",
    "    best_combo, best_score, best_model, best_accuracy = find_best_combo( , k_features_per_combo = i + 1)\n",
    "    print(i + 1, best_combo, best_score, best_accuracy, best_model)\n",
    "    best_combo_at_k[i + 1] = (best_combo, best_score, best_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Feature(\"The model should not recommend technological or medical interventions\")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect features to understand their nuances better\n",
    "\n",
    "best_individual_feature = best_combo_at_k[3][0][0]\n",
    "best_individual_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: The experimental features API is subject to change.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "FeatureGroup([\n",
       "   0: \"Blacklisted words and phrases in writing guidelines\",\n",
       "   1: \"Excluding specific programming languages or technologies\",\n",
       "   2: \"Instructions to suppress warnings or explanatory content\",\n",
       "   3: \"The model's limitations in accessing or modifying information\",\n",
       "   4: \"References to previous software versions (especially Python 2 and TLS 1.2)\",\n",
       "   5: \"Camelids and related animals\",\n",
       "   6: \"Concepts related to intelligence and learning\",\n",
       "   7: \"The model has made a mistake and the user is pointing it out\",\n",
       "   8: \"The model's comprehension of technical instructions or requirements\",\n",
       "   9: \"Ancient Roman landmarks and historical sites\"\n",
       "])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Nearest neighbours, ie feature group, of the best feature...\n",
    "\n",
    "feature_grp = client.features._experimental.neighbors(best_individual_feature)\n",
    "feature_grp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Feature(\"The model should not recommend technological or medical interventions\"),\n",
       " Feature(\"Specialized academic or scientific terminology\"),\n",
       " Feature(\"Proper nouns in media and entertainment contexts\"))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Anyways let's look at the best overall tree\n",
    "\n",
    "BEST_TREE_INDEX = 3\n",
    "best_features = best_combo_at_k[BEST_TREE_INDEX][0]\n",
    "best_tree = best_combo_at_k[BEST_TREE_INDEX][2]\n",
    "\n",
    "best_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.43.0 (0)\n",
       " -->\n",
       "<!-- Title: Tree Pages: 1 -->\n",
       "<svg width=\"1225pt\" height=\"433pt\"\n",
       " viewBox=\"0.00 0.00 1225.00 433.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 429)\">\n",
       "<title>Tree</title>\n",
       "<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-429 1221,-429 1221,4 -4,4\"/>\n",
       "<!-- 0 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>0</title>\n",
       "<path fill=\"#f7fbfe\" stroke=\"black\" d=\"M994.5,-425C994.5,-425 620.5,-425 620.5,-425 614.5,-425 608.5,-419 608.5,-413 608.5,-413 608.5,-354 608.5,-354 608.5,-348 614.5,-342 620.5,-342 620.5,-342 994.5,-342 994.5,-342 1000.5,-342 1006.5,-348 1006.5,-354 1006.5,-354 1006.5,-413 1006.5,-413 1006.5,-419 1000.5,-425 994.5,-425\"/>\n",
       "<text text-anchor=\"start\" x=\"616.5\" y=\"-409.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Specialized academic or scientific terminology ≤ 0.792</text>\n",
       "<text text-anchor=\"start\" x=\"772.5\" y=\"-394.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.5</text>\n",
       "<text text-anchor=\"start\" x=\"754.5\" y=\"-379.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 100</text>\n",
       "<text text-anchor=\"start\" x=\"750\" y=\"-364.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [49, 51]</text>\n",
       "<text text-anchor=\"start\" x=\"737\" y=\"-349.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = hallucinated</text>\n",
       "</g>\n",
       "<!-- 1 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>1</title>\n",
       "<path fill=\"#d7ebfa\" stroke=\"black\" d=\"M798,-306C798,-306 389,-306 389,-306 383,-306 377,-300 377,-294 377,-294 377,-235 377,-235 377,-229 383,-223 389,-223 389,-223 798,-223 798,-223 804,-223 810,-229 810,-235 810,-235 810,-294 810,-294 810,-300 804,-306 798,-306\"/>\n",
       "<text text-anchor=\"start\" x=\"385\" y=\"-290.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Proper nouns in media and entertainment contexts ≤ 0.142</text>\n",
       "<text text-anchor=\"start\" x=\"549.5\" y=\"-275.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.494</text>\n",
       "<text text-anchor=\"start\" x=\"545\" y=\"-260.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 90</text>\n",
       "<text text-anchor=\"start\" x=\"536\" y=\"-245.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [40, 50]</text>\n",
       "<text text-anchor=\"start\" x=\"523\" y=\"-230.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = hallucinated</text>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;1 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>0&#45;&gt;1</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M733.25,-341.91C714.91,-331.88 695.15,-321.07 676.42,-310.84\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"678.07,-307.75 667.61,-306.02 674.71,-313.89 678.07,-307.75\"/>\n",
       "<text text-anchor=\"middle\" x=\"674.65\" y=\"-326.31\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">True</text>\n",
       "</g>\n",
       "<!-- 6 -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>6</title>\n",
       "<path fill=\"#e88f4f\" stroke=\"black\" d=\"M1205,-306C1205,-306 840,-306 840,-306 834,-306 828,-300 828,-294 828,-294 828,-235 828,-235 828,-229 834,-223 840,-223 840,-223 1205,-223 1205,-223 1211,-223 1217,-229 1217,-235 1217,-235 1217,-294 1217,-294 1217,-300 1211,-306 1205,-306\"/>\n",
       "<text text-anchor=\"start\" x=\"836\" y=\"-290.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Specialized academic or scientific terminology ≤ 1.28</text>\n",
       "<text text-anchor=\"start\" x=\"983\" y=\"-275.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.18</text>\n",
       "<text text-anchor=\"start\" x=\"974\" y=\"-260.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 10</text>\n",
       "<text text-anchor=\"start\" x=\"974\" y=\"-245.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [9, 1]</text>\n",
       "<text text-anchor=\"start\" x=\"968\" y=\"-230.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = truthful</text>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;6 -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>0&#45;&gt;6</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M882.09,-341.91C900.52,-331.88 920.38,-321.07 939.19,-310.84\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"940.93,-313.88 948.04,-306.02 937.58,-307.73 940.93,-313.88\"/>\n",
       "<text text-anchor=\"middle\" x=\"940.96\" y=\"-326.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">False</text>\n",
       "</g>\n",
       "<!-- 2 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>2</title>\n",
       "<path fill=\"#c6e3f8\" stroke=\"black\" d=\"M573,-187C573,-187 12,-187 12,-187 6,-187 0,-181 0,-175 0,-175 0,-116 0,-116 0,-110 6,-104 12,-104 12,-104 573,-104 573,-104 579,-104 585,-110 585,-116 585,-116 585,-175 585,-175 585,-181 579,-187 573,-187\"/>\n",
       "<text text-anchor=\"start\" x=\"8\" y=\"-171.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">The model should not recommend technological or medical interventions ≤ 0.331</text>\n",
       "<text text-anchor=\"start\" x=\"248.5\" y=\"-156.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.486</text>\n",
       "<text text-anchor=\"start\" x=\"244\" y=\"-141.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 84</text>\n",
       "<text text-anchor=\"start\" x=\"235\" y=\"-126.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [35, 49]</text>\n",
       "<text text-anchor=\"start\" x=\"222\" y=\"-111.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = hallucinated</text>\n",
       "</g>\n",
       "<!-- 1&#45;&gt;2 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>1&#45;&gt;2</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M489.07,-222.91C462.34,-212.52 433.46,-201.29 406.28,-190.73\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"407.33,-187.38 396.75,-187.02 404.8,-193.91 407.33,-187.38\"/>\n",
       "</g>\n",
       "<!-- 5 -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>5</title>\n",
       "<path fill=\"#ea9a61\" stroke=\"black\" d=\"M716,-179.5C716,-179.5 615,-179.5 615,-179.5 609,-179.5 603,-173.5 603,-167.5 603,-167.5 603,-123.5 603,-123.5 603,-117.5 609,-111.5 615,-111.5 615,-111.5 716,-111.5 716,-111.5 722,-111.5 728,-117.5 728,-123.5 728,-123.5 728,-167.5 728,-167.5 728,-173.5 722,-179.5 716,-179.5\"/>\n",
       "<text text-anchor=\"start\" x=\"621.5\" y=\"-164.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.278</text>\n",
       "<text text-anchor=\"start\" x=\"621.5\" y=\"-149.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 6</text>\n",
       "<text text-anchor=\"start\" x=\"617\" y=\"-134.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [5, 1]</text>\n",
       "<text text-anchor=\"start\" x=\"611\" y=\"-119.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = truthful</text>\n",
       "</g>\n",
       "<!-- 1&#45;&gt;5 -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>1&#45;&gt;5</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M618.48,-222.91C625.34,-211.76 632.79,-199.66 639.69,-188.44\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"642.83,-190.02 645.09,-179.67 636.87,-186.35 642.83,-190.02\"/>\n",
       "</g>\n",
       "<!-- 3 -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>3</title>\n",
       "<path fill=\"#b3d9f5\" stroke=\"black\" d=\"M280,-68C280,-68 147,-68 147,-68 141,-68 135,-62 135,-56 135,-56 135,-12 135,-12 135,-6 141,0 147,0 147,0 280,0 280,0 286,0 292,-6 292,-12 292,-12 292,-56 292,-56 292,-62 286,-68 280,-68\"/>\n",
       "<text text-anchor=\"start\" x=\"169.5\" y=\"-52.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.472</text>\n",
       "<text text-anchor=\"start\" x=\"165\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 76</text>\n",
       "<text text-anchor=\"start\" x=\"156\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [29, 47]</text>\n",
       "<text text-anchor=\"start\" x=\"143\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = hallucinated</text>\n",
       "</g>\n",
       "<!-- 2&#45;&gt;3 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>2&#45;&gt;3</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M263.08,-103.73C256.7,-94.88 249.94,-85.51 243.53,-76.63\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"246.21,-74.36 237.52,-68.3 240.54,-78.46 246.21,-74.36\"/>\n",
       "</g>\n",
       "<!-- 4 -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>4</title>\n",
       "<path fill=\"#eeab7b\" stroke=\"black\" d=\"M423,-68C423,-68 322,-68 322,-68 316,-68 310,-62 310,-56 310,-56 310,-12 310,-12 310,-6 316,0 322,0 322,0 423,0 423,0 429,0 435,-6 435,-12 435,-12 435,-56 435,-56 435,-62 429,-68 423,-68\"/>\n",
       "<text text-anchor=\"start\" x=\"328.5\" y=\"-52.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.375</text>\n",
       "<text text-anchor=\"start\" x=\"328.5\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 8</text>\n",
       "<text text-anchor=\"start\" x=\"324\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [6, 2]</text>\n",
       "<text text-anchor=\"start\" x=\"318\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = truthful</text>\n",
       "</g>\n",
       "<!-- 2&#45;&gt;4 -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>2&#45;&gt;4</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M322.29,-103.73C328.75,-94.88 335.6,-85.51 342.09,-76.63\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"345.1,-78.44 348.17,-68.3 339.45,-74.31 345.1,-78.44\"/>\n",
       "</g>\n",
       "<!-- 7 -->\n",
       "<g id=\"node8\" class=\"node\">\n",
       "<title>7</title>\n",
       "<path fill=\"#e58139\" stroke=\"black\" d=\"M1002,-179.5C1002,-179.5 901,-179.5 901,-179.5 895,-179.5 889,-173.5 889,-167.5 889,-167.5 889,-123.5 889,-123.5 889,-117.5 895,-111.5 901,-111.5 901,-111.5 1002,-111.5 1002,-111.5 1008,-111.5 1014,-117.5 1014,-123.5 1014,-123.5 1014,-167.5 1014,-167.5 1014,-173.5 1008,-179.5 1002,-179.5\"/>\n",
       "<text text-anchor=\"start\" x=\"916.5\" y=\"-164.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n",
       "<text text-anchor=\"start\" x=\"907.5\" y=\"-149.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 5</text>\n",
       "<text text-anchor=\"start\" x=\"903\" y=\"-134.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [5, 0]</text>\n",
       "<text text-anchor=\"start\" x=\"897\" y=\"-119.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = truthful</text>\n",
       "</g>\n",
       "<!-- 6&#45;&gt;7 -->\n",
       "<g id=\"edge7\" class=\"edge\">\n",
       "<title>6&#45;&gt;7</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M997.87,-222.91C991.1,-211.76 983.76,-199.66 976.95,-188.44\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"979.81,-186.4 971.63,-179.67 973.82,-190.03 979.81,-186.4\"/>\n",
       "</g>\n",
       "<!-- 8 -->\n",
       "<g id=\"node9\" class=\"node\">\n",
       "<title>8</title>\n",
       "<path fill=\"#eca06a\" stroke=\"black\" d=\"M1145,-179.5C1145,-179.5 1044,-179.5 1044,-179.5 1038,-179.5 1032,-173.5 1032,-167.5 1032,-167.5 1032,-123.5 1032,-123.5 1032,-117.5 1038,-111.5 1044,-111.5 1044,-111.5 1145,-111.5 1145,-111.5 1151,-111.5 1157,-117.5 1157,-123.5 1157,-123.5 1157,-167.5 1157,-167.5 1157,-173.5 1151,-179.5 1145,-179.5\"/>\n",
       "<text text-anchor=\"start\" x=\"1055\" y=\"-164.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.32</text>\n",
       "<text text-anchor=\"start\" x=\"1050.5\" y=\"-149.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 5</text>\n",
       "<text text-anchor=\"start\" x=\"1046\" y=\"-134.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [4, 1]</text>\n",
       "<text text-anchor=\"start\" x=\"1040\" y=\"-119.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = truthful</text>\n",
       "</g>\n",
       "<!-- 6&#45;&gt;8 -->\n",
       "<g id=\"edge8\" class=\"edge\">\n",
       "<title>6&#45;&gt;8</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1047.48,-222.91C1054.34,-211.76 1061.79,-199.66 1068.69,-188.44\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1071.83,-190.02 1074.09,-179.67 1065.87,-186.35 1071.83,-190.02\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.sources.Source at 0x7665828771f0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's visualize the tree\n",
    "\n",
    "import graphviz\n",
    "\n",
    "dot_data = tree.export_graphviz(best_tree, out_file=None, feature_names=[feature.label for feature in best_features], class_names=['truthful', 'hallucinated'], filled=True, rounded=True, special_characters=True)\n",
    "graph = graphviz.Source(dot_data)\n",
    "graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's inspect some feature activations for ourselves...\n",
    "\n",
    "import concurrent.futures as futures\n",
    "import tqdm\n",
    "\n",
    "def get_feature_activations(client, variant, examples, features, k=50):\n",
    "    \"\"\"\n",
    "    Get feature activations for a set of examples using Goodfire\n",
    "    \"\"\"\n",
    "    samples = []\n",
    "\n",
    "    with futures.ThreadPoolExecutor(max_workers=1) as executor:\n",
    "        futures_list = []\n",
    "\n",
    "        for example in examples:\n",
    "            futures_list.append(\n",
    "                executor.submit(\n",
    "                    client.features.inspect,\n",
    "                    example,\n",
    "                    model=variant,\n",
    "                    features=features,\n",
    "                )\n",
    "            )\n",
    "\n",
    "        for future in tqdm.tqdm(futures_list):\n",
    "            context = future.result()\n",
    "            features = context.top(k=k)\n",
    "            samples.append(features)\n",
    "\n",
    "    return samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'role': 'user',\n",
       "   'content': 'You are a medical expert and this is a multiple choice exam question. Please respond with the integer index of the CORRECT answer only; [0,1,2,3].\\n\\nMental disorders in the Diagnostic and Statistical Manual of the American Psychiatric Association, following a personality disorder that belongs to the species (cluster) with three other different?\\n\\nOptions: {\"0\": \"Borderline\", \"1\": \"Antisocial\", \"2\": \"Paranoid\", \"3\": \"Drama type\"}'},\n",
       "  {'role': 'assistant', 'content': '3'}]]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_1[0:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.01it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[FeatureActivations(\n",
       "    0: (Feature(\"Specialized academic or scientific terminology\"), 0.6015625)\n",
       "    1: (Feature(\"The model should not recommend technological or medical interventions\"), 0)\n",
       "    2: (Feature(\"Proper nouns in media and entertainment contexts\"), 0)\n",
       "    3: (Feature(\"Mathematical derivation steps during integration problems\"), 0)\n",
       "    4: (Feature(\"Contrastive conjunctions balancing difficulties with solutions\"), 0)\n",
       "    5: (Feature(\"The model's turn to begin responding to user query\"), 0)\n",
       "    6: (Feature(\"The model is providing troubleshooting steps or guidance\"), 0)\n",
       "    7: (Feature(\"Punctuation marks used for pacing and engagement in teaching contexts\"), 0)\n",
       "    8: (Feature(\"The assistant is providing a list of options and asking for user selection\"), 0)\n",
       "    9: (Feature(\"The model's turn to speak\"), 0)\n",
       "    ...\n",
       "    21: (Feature(\"The assistant is acknowledging or validating human emotions and experiences\"), 0)\n",
       " )]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_activations = get_feature_activations(client, variant, dataset_1[0:1], best_features)\n",
    "example_activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import goodfire\n",
    "from typing import List, Dict, Tuple, Any\n",
    "import numpy as np\n",
    "\n",
    "class HallucinationClassifier:\n",
    "    def __init__(self, model_path: str, api_key: str):\n",
    "        \"\"\"\n",
    "        Initialize the hallucination classifier with a saved model and features.\n",
    "        \n",
    "        Args:\n",
    "            model_path: Path to the saved pickle file containing both the model and features\n",
    "            api_key: Goodfire API key for accessing the service\n",
    "        \"\"\"\n",
    "        # Load the model and features\n",
    "        with open(model_path, 'rb') as f:\n",
    "            model_data = pickle.load(f)\n",
    "            self.model = model_data['model']\n",
    "            self.features = model_data['features']\n",
    "        self.client = goodfire.Client(api_key)\n",
    "        self.variant = goodfire.Variant(\"meta-llama/Meta-Llama-3-8B-Instruct\")\n",
    "\n",
    "    def _format_prompt(self, question: str) -> List[Dict[str, str]]:\n",
    "        \"\"\"Format a question into the expected prompt structure.\"\"\"\n",
    "        introduction = (\"You are a medical expert and this is a multiple choice exam question. \"\n",
    "                      \"Please respond with the integer index of the CORRECT answer only; [0,1,2,3].\")\n",
    "        return [{\"role\": \"user\", \"content\": f\"{introduction}\\n\\n{question}\"}]\n",
    "\n",
    "    def _get_feature_activations(self, prompt: List[Dict[str, str]]) -> List[float]:\n",
    "        \"\"\"Get feature activations for the input prompt.\"\"\"\n",
    "        context = self.client.features.inspect(\n",
    "            prompt,\n",
    "            model=self.variant,\n",
    "            features=self.features\n",
    "        )\n",
    "        \n",
    "        # Get activations for our specific features\n",
    "        activations = []\n",
    "        features_dict = {f.uuid: 0.0 for f in self.features}\n",
    "        \n",
    "        for feature_act in context.top(k=len(self.features)):\n",
    "            if feature_act.feature.uuid in features_dict:\n",
    "                features_dict[feature_act.feature.uuid] = feature_act.activation\n",
    "        \n",
    "        # Maintain order matching the original features\n",
    "        for feature in self.features:\n",
    "            activations.append(features_dict[feature.uuid])\n",
    "            \n",
    "        return activations\n",
    "\n",
    "    def predict(self, question: str, debug: bool = False) -> Tuple[int, float]:\n",
    "        \"\"\"\n",
    "        Predict whether a given question-answer pair is likely to contain hallucination.\n",
    "        \n",
    "        Args:\n",
    "            question: The question text\n",
    "            debug: If True, print debugging information about feature activations\n",
    "            \n",
    "        Returns:\n",
    "            Tuple containing:\n",
    "            - Prediction (0 for truthful, 1 for hallucinated)\n",
    "            - Confidence score (probability of the predicted class)\n",
    "        \"\"\"\n",
    "        # Format the prompt\n",
    "        prompt = self._format_prompt(question)\n",
    "        \n",
    "        # Get feature activations\n",
    "        activations = self._get_feature_activations(prompt)\n",
    "        \n",
    "        if debug:\n",
    "            print(\"\\nFeature Activations:\")\n",
    "            for feature, activation in zip(self.features, activations):\n",
    "                print(f\"{feature.label}: {activation:.4f}\")\n",
    "            \n",
    "            # Get the decision path\n",
    "            decision_path = self.model.decision_path([activations])\n",
    "            feature_importance = self.model.feature_importances_\n",
    "            \n",
    "            print(\"\\nFeature Importance in Model:\")\n",
    "            for feature, importance in zip(self.features, feature_importance):\n",
    "                print(f\"{feature.label}: {importance:.4f}\")\n",
    "            \n",
    "            print(\"\\nDecision Path:\")\n",
    "            node_indicator = decision_path[0]\n",
    "            leaf_id = self.model.apply([activations])[0]\n",
    "            \n",
    "            # Get thresholds and feature indices for each node in path\n",
    "            for node_id in node_indicator.indices:\n",
    "                if node_id != leaf_id:\n",
    "                    feature_idx = self.model.tree_.feature[node_id]\n",
    "                    threshold = self.model.tree_.threshold[node_id]\n",
    "                    feature_name = self.features[feature_idx].label\n",
    "                    feature_value = activations[feature_idx]\n",
    "                    print(f\"Node {node_id}: {feature_name} = {feature_value:.4f} {'<=' if feature_value <= threshold else '>'} {threshold:.4f}\")\n",
    "        \n",
    "        # Make prediction\n",
    "        prediction = self.model.predict([activations])[0]\n",
    "        probabilities = self.model.predict_proba([activations])[0]\n",
    "        confidence = probabilities[prediction]\n",
    "        \n",
    "        if debug:\n",
    "            print(f\"\\nProbabilities:\")\n",
    "            print(f\"Truthful: {probabilities[0]:.4f}\")\n",
    "            print(f\"Hallucinated: {probabilities[1]:.4f}\")\n",
    "        \n",
    "        return int(prediction), float(confidence)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model_and_features(model, features, output_path: str):\n",
    "    \"\"\"Save both the sklearn decision tree model and Goodfire features to a file.\n",
    "    \n",
    "    Args:\n",
    "        model: The trained sklearn decision tree model\n",
    "        features: The Goodfire features used by the model\n",
    "        output_path: Path where to save the pickle file\n",
    "    \"\"\"\n",
    "    model_data = {\n",
    "        'model': model,\n",
    "        'features': features\n",
    "    }\n",
    "    with open(output_path, 'wb') as f:\n",
    "        pickle.dump(model_data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model and best_features\n",
    "\n",
    "model_path = \"../assets/hallucination_model.pkl\"\n",
    "save_model_and_features(best_tree, best_features, model_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the classifier (now simpler, no need to pass features separately)\n",
    "classifier = HallucinationClassifier(\n",
    "    model_path=model_path,\n",
    "    api_key=api_key\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are a medical expert and this is a multiple choice exam question. Please respond with the integer index of the CORRECT answer only; [0,1,2,3].\n",
      "\n",
      "Mental disorders in the Diagnostic and Statistical Manual of the American Psychiatric Association, following a personality disorder that belongs to the species (cluster) with three other different?\n",
      "\n",
      "Options: {\"0\": \"Borderline\", \"1\": \"Antisocial\", \"2\": \"Paranoid\", \"3\": \"Drama type\"}\n",
      "\n",
      "Feature Activations:\n",
      "The model should not recommend technological or medical interventions: 0.0000\n",
      "Specialized academic or scientific terminology: 0.6562\n",
      "Proper nouns in media and entertainment contexts: 0.0000\n",
      "\n",
      "Feature Importance in Model:\n",
      "The model should not recommend technological or medical interventions: 0.2505\n",
      "Specialized academic or scientific terminology: 0.5017\n",
      "Proper nouns in media and entertainment contexts: 0.2479\n",
      "\n",
      "Decision Path:\n",
      "Node 0: Specialized academic or scientific terminology = 0.6562 <= 0.7922\n",
      "Node 1: Proper nouns in media and entertainment contexts = 0.0000 <= 0.1416\n",
      "Node 2: The model should not recommend technological or medical interventions = 0.0000 <= 0.3314\n",
      "\n",
      "Probabilities:\n",
      "Truthful: 0.3816\n",
      "Hallucinated: 0.6184\n",
      "Prediction: Hallucinated\n",
      "Confidence: 0.62\n"
     ]
    }
   ],
   "source": [
    "# Make predictions - Example from hallucinations dataframe\n",
    "prompt_example = hallucinated_examples.iloc[0]['prompt']\n",
    "print(prompt_example)\n",
    "\n",
    "prediction, confidence = classifier.predict(prompt_example, debug=True)\n",
    "\n",
    "print(f\"Prediction: {'Hallucinated' if prediction == 1 else 'Truthful'}\")\n",
    "print(f\"Confidence: {confidence:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are a medical expert and this is a multiple choice exam question. Please respond with the integer index of the CORRECT answer only; [0,1,2,3].\n",
      "\n",
      "Oxygen saturation of venous blood is ?\n",
      "\n",
      "Options: {\"0\": \"30%\", \"1\": \"50%\", \"2\": \"70%\", \"3\": \"90%\"}\n",
      "\n",
      "Feature Activations:\n",
      "The model should not recommend technological or medical interventions: 0.0000\n",
      "Specialized academic or scientific terminology: 0.0000\n",
      "Proper nouns in media and entertainment contexts: 0.0000\n",
      "\n",
      "Feature Importance in Model:\n",
      "The model should not recommend technological or medical interventions: 0.2505\n",
      "Specialized academic or scientific terminology: 0.5017\n",
      "Proper nouns in media and entertainment contexts: 0.2479\n",
      "\n",
      "Decision Path:\n",
      "Node 0: Specialized academic or scientific terminology = 0.0000 <= 0.7922\n",
      "Node 1: Proper nouns in media and entertainment contexts = 0.0000 <= 0.1416\n",
      "Node 2: The model should not recommend technological or medical interventions = 0.0000 <= 0.3314\n",
      "\n",
      "Probabilities:\n",
      "Truthful: 0.3816\n",
      "Hallucinated: 0.6184\n",
      "Prediction:  1\n",
      "Prediction: Hallucinated\n",
      "Confidence: 0.62\n"
     ]
    }
   ],
   "source": [
    "# Make predictions - Example from truthful dataframe\n",
    "\n",
    "prompt_example = truthful_examples.iloc[50]['prompt']\n",
    "print(prompt_example)\n",
    "\n",
    "prediction, confidence = classifier.predict(prompt_example,debug=True)\n",
    "print(\"Prediction: \", prediction)\n",
    "print(f\"Prediction: {'Hallucinated' if prediction == 1 else 'Truthful'}\")\n",
    "print(f\"Confidence: {confidence:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EVALUATION ON TRAIN & TEST DATASETS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "def evaluate_model_predictions(classifier, truthful_examples, hallucinated_examples):\n",
    "    \"\"\"\n",
    "    Evaluate model predictions across all examples.\n",
    "    \n",
    "    Args:\n",
    "        classifier: The HallucinationClassifier instance\n",
    "        truthful_examples: DataFrame containing truthful examples\n",
    "        hallucinated_examples: DataFrame containing hallucinated examples\n",
    "    \"\"\"\n",
    "    # Store results\n",
    "    results = []\n",
    "    \n",
    "    # Process truthful examples\n",
    "    print(\"\\nProcessing truthful examples...\")\n",
    "    for idx, row in tqdm(truthful_examples.iterrows(), total=len(truthful_examples)):\n",
    "        prediction, confidence = classifier.predict(row['prompt'])\n",
    "        results.append({\n",
    "            'true_label': 'truthful',\n",
    "            'predicted': 'hallucinated' if prediction == 1 else 'truthful',\n",
    "            'confidence': confidence\n",
    "        })\n",
    "    \n",
    "    # Process hallucinated examples\n",
    "    print(\"\\nProcessing hallucinated examples...\")\n",
    "    for idx, row in tqdm(hallucinated_examples.iterrows(), total=len(hallucinated_examples)):\n",
    "        prediction, confidence = classifier.predict(row['prompt'])\n",
    "        results.append({\n",
    "            'true_label': 'hallucinated',\n",
    "            'predicted': 'hallucinated' if prediction == 1 else 'truthful',\n",
    "            'confidence': confidence\n",
    "        })\n",
    "    \n",
    "    # Convert to DataFrame for analysis\n",
    "    results_df = pd.DataFrame(results)\n",
    "    \n",
    "    # Calculate overall statistics\n",
    "    total_predictions = len(results_df)\n",
    "    print(\"\\nOverall Statistics:\")\n",
    "    print(f\"Total examples evaluated: {total_predictions}\")\n",
    "    \n",
    "    # Prediction distribution\n",
    "    pred_dist = results_df['predicted'].value_counts()\n",
    "    print(\"\\nPrediction Distribution:\")\n",
    "    for pred, count in pred_dist.items():\n",
    "        percentage = (count/total_predictions) * 100\n",
    "        print(f\"{pred}: {count} ({percentage:.1f}%)\")\n",
    "    \n",
    "    # Confusion Matrix\n",
    "    print(\"\\nConfusion Matrix:\")\n",
    "    confusion = pd.crosstab(results_df['true_label'], results_df['predicted'])\n",
    "    print(confusion)\n",
    "    \n",
    "    # Calculate metrics by class\n",
    "    print(\"\\nMetrics by True Label:\")\n",
    "    for label in ['truthful', 'hallucinated']:\n",
    "        class_results = results_df[results_df['true_label'] == label]\n",
    "        correct = (class_results['true_label'] == class_results['predicted']).sum()\n",
    "        total = len(class_results)\n",
    "        accuracy = (correct/total) * 100\n",
    "        avg_confidence = class_results['confidence'].mean()\n",
    "        \n",
    "        print(f\"\\n{label.title()} Examples:\")\n",
    "        print(f\"Accuracy: {accuracy:.1f}%\")\n",
    "        print(f\"Average Confidence: {avg_confidence:.3f}\")\n",
    "    \n",
    "    # Return the results DataFrame for further analysis if needed\n",
    "    return results_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TRAIN DATASET EVALUATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing truthful examples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [01:36<00:00,  1.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing hallucinated examples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [01:34<00:00,  1.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Overall Statistics:\n",
      "Total examples evaluated: 200\n",
      "\n",
      "Prediction Distribution:\n",
      "hallucinated: 144 (72.0%)\n",
      "truthful: 56 (28.0%)\n",
      "\n",
      "Confusion Matrix:\n",
      "predicted     hallucinated  truthful\n",
      "true_label                          \n",
      "hallucinated            86        14\n",
      "truthful                58        42\n",
      "\n",
      "Metrics by True Label:\n",
      "\n",
      "Truthful Examples:\n",
      "Accuracy: 42.0%\n",
      "Average Confidence: 0.407\n",
      "\n",
      "Hallucinated Examples:\n",
      "Accuracy: 86.0%\n",
      "Average Confidence: 0.548\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "## TRAINING DATASET EVALUATION\n",
    "\n",
    "# Assuming classifier is already initialized\n",
    "results_df = evaluate_model_predictions(classifier, truthful_examples, hallucinated_examples)\n",
    "\n",
    "# You can do additional analysis on results_df if needed\n",
    "# For example, look at high confidence mistakes:\n",
    "high_conf_mistakes = results_df[\n",
    "    (results_df['true_label'] != results_df['predicted']) & \n",
    "    (results_df['confidence'] > 0.8)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Performance Interpretation\n",
    "\n",
    "The recall of 86% is quite good - the model catches 86% of all hallucinations. This aligns with your goal of preventing medical hallucinations, as it misses relatively few of them.\n",
    "The precision of 59.7% means that when the model flags something as a hallucination, it's right about 60% of the time. The relatively lower precision indicates that the model is somewhat aggressive in flagging content as hallucinated.\n",
    "This trade-off (high recall, moderate precision) might be acceptable for the medical use case, as:\n",
    "\n",
    "In medical contexts, missing a hallucination (false negative) could be more dangerous than incorrectly flagging truthful content (false positive)\n",
    "False positives can be manually reviewed, while missed hallucinations might go unnoticed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TEST DATASET EVALUATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
