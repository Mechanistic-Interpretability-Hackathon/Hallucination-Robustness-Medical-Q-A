{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ast\n",
    "import json\n",
    "from typing import Optional, Tuple\n",
    "\n",
    "def get_balanced_samples(df: pd.DataFrame, \n",
    "                        n_per_class: Optional[int] = None,\n",
    "                        train_fraction: float = 0.8,\n",
    "                        random_state: Optional[int] = None) -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Randomly sample an equal number of records where hallucinated is True and False,\n",
    "    split into training and test sets, and format prompts for each row.\n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame): Input DataFrame with 'hallucinated', 'question', and 'options' columns\n",
    "        n_per_class (int, optional): Number of samples to take from each class.\n",
    "                                   If None, uses the size of the smaller class.\n",
    "        train_fraction (float): Fraction of data to use for training (default: 0.8)\n",
    "        random_state (int, optional): Random seed for reproducibility\n",
    "    \n",
    "    Returns:\n",
    "        Tuple[pd.DataFrame, pd.DataFrame]: (train_df, test_df) containing balanced samples\n",
    "                                         with formatted prompts\n",
    "    \"\"\"\n",
    "    if not 0 < train_fraction < 1:\n",
    "        raise ValueError(\"train_fraction must be between 0 and 1\")\n",
    "    \n",
    "    # Ensure hallucinated column is boolean\n",
    "    df = df.copy()\n",
    "\n",
    "    # Filter by activation if the column exists\n",
    "    if 'activation' in df.columns:\n",
    "        original_len = len(df)\n",
    "        df = df[df['activation'] == 0]\n",
    "        filtered_len = len(df)\n",
    "\n",
    "        if filtered_len == 0:\n",
    "            raise ValueError(\"No rows remaining after filtering activation = 0\")\n",
    "\n",
    "    # Ensure hallucinated column is boolean\n",
    "    df['hallucinated'] = df['hallucinated'].astype(bool)\n",
    "    \n",
    "    # Split into True and False groups\n",
    "    true_samples = df[df['hallucinated'] == True]\n",
    "    false_samples = df[df['hallucinated'] == False]\n",
    "    \n",
    "    # Get counts\n",
    "    n_true = len(true_samples)\n",
    "    n_false = len(false_samples)\n",
    "    \n",
    "    # If n_per_class not specified, use size of smaller group\n",
    "    if n_per_class is None:\n",
    "        n_per_class = min(n_true, n_false)\n",
    "    \n",
    "    # Verify we have enough samples\n",
    "    if n_per_class > min(n_true, n_false):\n",
    "        raise ValueError(f\"Requested {n_per_class} samples per class but smallest class only has {min(n_true, n_false)} samples\")\n",
    "    \n",
    "    # Sample from each group\n",
    "    sampled_true = true_samples.sample(n=n_per_class, random_state=random_state)\n",
    "    sampled_false = false_samples.sample(n=n_per_class, random_state=random_state)\n",
    "    \n",
    "    # Calculate number of training samples (ensuring even split between classes)\n",
    "    n_train_per_class = int(n_per_class * train_fraction)\n",
    "    \n",
    "    # Split each class into train and test\n",
    "    train_true = sampled_true.iloc[:n_train_per_class]\n",
    "    test_true = sampled_true.iloc[n_train_per_class:]\n",
    "    \n",
    "    train_false = sampled_false.iloc[:n_train_per_class]\n",
    "    test_false = sampled_false.iloc[n_train_per_class:]\n",
    "    \n",
    "    # Combine and shuffle train and test sets\n",
    "    train_df = pd.concat([train_true, train_false])\n",
    "    train_df = train_df.sample(frac=1, random_state=random_state).reset_index(drop=True)\n",
    "    \n",
    "    test_df = pd.concat([test_true, test_false])\n",
    "    test_df = test_df.sample(frac=1, random_state=random_state).reset_index(drop=True)\n",
    "    \n",
    "    \n",
    "    # Format prompts for both datasets\n",
    "    def format_prompts(df):\n",
    "        introduction = (\"You are a medical expert and this is a multiple choice exam question. \"\n",
    "                       \"Please respond with the integer index of the CORRECT answer only; [0,1,2,3].\")\n",
    "        \n",
    "        formatted_df = df.copy()\n",
    "        formatted_prompts = []\n",
    "        \n",
    "        for _, row in df.iterrows():\n",
    "            question = row['question']\n",
    "            \n",
    "            # Parse options\n",
    "            if isinstance(row['options'], str):\n",
    "                options_dict = ast.literal_eval(row['options'])\n",
    "            elif isinstance(row['options'], list) and len(row['options']) > 0:\n",
    "                options_dict = row['options'][0]\n",
    "            else:\n",
    "                options_dict = row['options']\n",
    "            \n",
    "            # Filter out 'correct answer' from options\n",
    "            options_filtered = {k: v for k, v in options_dict.items() if k != 'correct answer'}\n",
    "            options_formatted = \"Options: \" + json.dumps(options_filtered)\n",
    "            \n",
    "            # Construct prompt\n",
    "            prompt = f\"{introduction}\\n\\n{question}\\n\\n{options_formatted}\"\n",
    "            formatted_prompts.append(prompt)\n",
    "        \n",
    "        formatted_df['prompt'] = formatted_prompts\n",
    "        return formatted_df\n",
    "    \n",
    "    # Apply prompt formatting to both datasets\n",
    "    train_df = format_prompts(train_df)\n",
    "    test_df = format_prompts(test_df)\n",
    "    \n",
    "    print(f\"Created balanced samples with {n_per_class} records per class\")\n",
    "    print(f\"Training set: {len(train_df)} records ({n_train_per_class} per class)\")\n",
    "    print(f\"Test set: {len(test_df)} records ({n_per_class - n_train_per_class} per class)\")\n",
    "    print(\"\\nClass distribution in training set:\")\n",
    "    print(train_df['hallucinated'].value_counts())\n",
    "    print(\"\\nClass distribution in test set:\")\n",
    "    print(test_df['hallucinated'].value_counts())\n",
    "    \n",
    "    return train_df, test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created balanced samples with 1172 records per class\n",
      "Training set: 1874 records (937 per class)\n",
      "Test set: 470 records (235 per class)\n",
      "\n",
      "Class distribution in training set:\n",
      "hallucinated\n",
      "False    937\n",
      "True     937\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Class distribution in test set:\n",
      "hallucinated\n",
      "True     235\n",
      "False    235\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "file_path = '../data/baseline_results.tsv'\n",
    "\n",
    "# Read the TSV file\n",
    "df = pd.read_csv(file_path, sep='\\t')\n",
    "\n",
    "# Get balanced samples with train/test split\n",
    "train_data, val_data = get_balanced_samples(\n",
    "    df=df,\n",
    "    # n_per_class=125,\n",
    "    train_fraction=0.8,\n",
    "    random_state=42\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7100, 9), (1874, 9), (470, 9))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape, train_data.shape, val_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import goodfire as gf\n",
    "import os\n",
    "\n",
    "# Get API key\n",
    "api_key = os.getenv('GOODFIRE_API_KEY')\n",
    "client  = gf.Client(api_key)\n",
    "variant = gf.Variant(\"meta-llama/Meta-Llama-3.1-8B-Instruct\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "from typing import List, Tuple\n",
    "\n",
    "\n",
    "# 1. Prepare Dataset\n",
    "def prepare_dataset(train_data: pd.DataFrame, hallucinated: bool=True) -> Tuple[List, pd.DataFrame]: \n",
    "  \"\"\"Prepare a dataset from training data based on hallucinated or truthful examples. \n",
    "  Args:\n",
    "      train_data (pd.DataFrame): DataFrame containing training data with 'hallucinated' and 'prompt' columns.\n",
    "      hallucinated (bool): Boolean indicating whether to filter for hallucinated examples.\n",
    "  Returns:\n",
    "        tuple: A tuple containing:\n",
    "            - dataset (list): A list of conversations in the required format for each example.\n",
    "            - filtered_examples (pd.DataFrame): The filtered DataFrame containing only the examples \n",
    "                                                corresponding to the specified hallucinated value.\n",
    "  \"\"\"\n",
    "  filtered_examples = train_data[train_data['hallucinated'] == hallucinated]\n",
    "  dataset = [\n",
    "    [\n",
    "      {\"role\": \"user\", \"content\": prompt},\n",
    "      {\"role\": \"assistant\", \"content\": \"3\"} \n",
    "    ] for prompt in filtered_examples[\"prompt\"].tolist()\n",
    "  ]\n",
    "  return dataset, filtered_examples\n",
    "\n",
    "\n",
    "# 2. Chunk Dataset\n",
    "def chunk_dataset(dataset, chunk_size=64): \n",
    "  \"\"\"\n",
    "    Split a dataset into smaller chunks for API processing.\n",
    "    Args:\n",
    "        dataset: The dataset to chunk.\n",
    "        chunk_size: Maximum size of each chunk.\n",
    "    Yields:\n",
    "        Chunks of the dataset.\n",
    "    \"\"\"\n",
    "  for i in range(0, len(dataset), chunk_size):\n",
    "    yield dataset[i:i+chunk_size]\n",
    "    \n",
    "\n",
    "# 3. Contrast Features\n",
    "def contrast_features(client, variant, dataset_1_chunks, dataset_2_chunks, top_k=50):\n",
    "  \"\"\"\n",
    "    Perform feature contrast for two datasets using Goodfire.\n",
    "    Args:\n",
    "        client: The Goodfire client instance.\n",
    "        variant: The model variant to use.\n",
    "        dataset_1_chunks: List of dataset chunks for the first class.\n",
    "        dataset_2_chunks: List of dataset chunks for the second class.\n",
    "        top_k: Number of top features to extract.\n",
    "    Returns:\n",
    "        A tuple of feature groups for dataset_1 and dataset_2.\n",
    "    \"\"\" \n",
    "  hallucinated_features = None  # Initialize to None\n",
    "  truthful_features = None \n",
    "  \n",
    "  for d1_chunk, d2_chunk in zip(dataset_1_chunks, dataset_2_chunks):\n",
    "    hallucinated_chunk_features, truthful_chunk_features = client.features.contrast(\n",
    "      dataset_1=d1_chunk, \n",
    "      dataset_2=d2_chunk, \n",
    "      model=variant, \n",
    "      top_k=top_k\n",
    "    )\n",
    "    if hallucinated_features is None:\n",
    "        hallucinated_features = hallucinated_chunk_features\n",
    "    else:\n",
    "        hallucinated_features = hallucinated_features.union(hallucinated_chunk_features)\n",
    "\n",
    "    if truthful_features is None:\n",
    "        truthful_features = truthful_chunk_features\n",
    "    else:\n",
    "        truthful_features = truthful_features.union(truthful_chunk_features)\n",
    "\n",
    "  return hallucinated_features, truthful_features\n",
    "  \n",
    "\n",
    "\n",
    "# 4. Rerank Features\n",
    "def rerank_features(client, features, query, model, top_k=50):\n",
    "  \"\"\"\n",
    "  Rerank features based on a query.\n",
    "  Args:\n",
    "      client: The Goodfire client instance.\n",
    "      features: The features to rerank.\n",
    "      query: Query string for reranking.\n",
    "      model: The model variant to use.\n",
    "      top_k: Number of top features to return.\n",
    "  Returns:\n",
    "      Reranked features.\n",
    "  \"\"\"\n",
    "  return client.features.rerank(\n",
    "    features=features,\n",
    "    query=query,\n",
    "    model=model,\n",
    "    top_k=top_k\n",
    "  )\n",
    "  \n",
    "  \n",
    "# 5. Combine Features \n",
    "def combine_features(hallucinated_features, truthful_features):\n",
    "  \"\"\"\n",
    "  Combine two sets of features into a single set.\n",
    "  Args:\n",
    "      hallucinated_features: Features from the hallucinated dataset.\n",
    "      truthful_features: Features from the truthful dataset.\n",
    "  Returns:\n",
    "      A combined set of features.\n",
    "  \"\"\"\n",
    "  return hallucinated_features | truthful_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FeatureGroup([\n",
      "   0: \"Medical diagnostic procedures and test ordering sequences\",\n",
      "   1: \"Medical discussions of urinalysis and urine testing procedures\",\n",
      "   2: \"Detailed surgical procedure descriptions in medical documentation\",\n",
      "   3: \"Start of potentially sensitive conversations requiring moderation\",\n",
      "   4: \"Offensive request from the user\",\n",
      "   5: \"Offensive request from the user\",\n",
      "   6: \"Medical discourse about lung conditions and pathology\",\n",
      "   7: \"Start of potentially sensitive conversation segments requiring moderation\",\n",
      "   8: \"Medical treatment protocols and medication administration details\",\n",
      "   ...\n",
      "   90: \"Food safety guidelines and bacterial contamination prevention\"\n",
      "])\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Prepare datasets\n",
    "dataset_1, hallucinated_examples = prepare_dataset(train_data, hallucinated=True)\n",
    "dataset_2, truthful_examples = prepare_dataset(train_data, hallucinated=False)\n",
    "\n",
    "# Step 2: Chunk datasets\n",
    "chunk_size = 64\n",
    "dataset_1_chunks = list(chunk_dataset(dataset_1, chunk_size))\n",
    "dataset_2_chunks = list(chunk_dataset(dataset_2, chunk_size))\n",
    "\n",
    "# Step 3: Contrast features\n",
    "hallucinated_features, truthful_features = contrast_features(\n",
    "    client,\n",
    "    variant,\n",
    "    dataset_1_chunks,\n",
    "    dataset_2_chunks,\n",
    "    top_k=50\n",
    ")\n",
    "# query1_ = \"medical response hallucinated\",\n",
    "# Step 4: Rerank features\n",
    "hallucinated_features = rerank_features(\n",
    "    client,\n",
    "    hallucinated_features,\n",
    "    query=\"unknown medical query\",\n",
    "    model=variant,\n",
    "    top_k=50\n",
    ")\n",
    "\n",
    "truthful_features = rerank_features(\n",
    "    client,\n",
    "    truthful_features,\n",
    "    query=\"medical query\",\n",
    "    model=variant,\n",
    "    top_k=50\n",
    ")\n",
    "\n",
    "# Step 5: Combine features\n",
    "features_to_look_at = combine_features(hallucinated_features, truthful_features)\n",
    "\n",
    "# Final Output\n",
    "print(features_to_look_at)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "\n",
    "\n",
    "class FeatureSearch:\n",
    "    \"\"\"A class for systematically searching through \n",
    "      combinations of features to evaluate their predictive power.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, feature_group):\n",
    "        self.feature_group = feature_group\n",
    "\n",
    "    def grid(self, k_features_per_combo: int = 2):\n",
    "        \"\"\"Perform a grid search over all possible combinations of features.\n",
    "        Args:\n",
    "            k_features_per_combo (int): The number of features to include in each combination.\n",
    "        Returns:\n",
    "            list: All possible k-sized combinations of features from the feature group.\n",
    "        \"\"\"\n",
    "\n",
    "        # Get all possible combinations of features\n",
    "        return list(combinations(self.feature_group, k_features_per_combo))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "async_client = gf.AsyncClient(api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing truthful features...\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "k must be greater than the number of features to use for classification",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 67\u001b[0m\n\u001b[1;32m     60\u001b[0m     hallucinated_class_features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m _get_feature_acts_for_sample_class(\n\u001b[1;32m     61\u001b[0m         hallucinated_examples, features_to_look_at, k\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m\n\u001b[1;32m     62\u001b[0m     )\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m truthful_class_features, hallucinated_class_features\n\u001b[0;32m---> 67\u001b[0m truthful_class_features, hallucinated_class_features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m process_all_classes()\n",
      "Cell \u001b[0;32mIn[30], line 55\u001b[0m, in \u001b[0;36mprocess_all_classes\u001b[0;34m()\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprocess_all_classes\u001b[39m():\n\u001b[1;32m     54\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mComputing truthful features...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 55\u001b[0m     truthful_class_features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m _get_feature_acts_for_sample_class(\n\u001b[1;32m     56\u001b[0m         truthful_examples, features_to_look_at, k\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m\n\u001b[1;32m     57\u001b[0m     )\n\u001b[1;32m     59\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mComputing hallucinated features...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     60\u001b[0m     hallucinated_class_features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m _get_feature_acts_for_sample_class(\n\u001b[1;32m     61\u001b[0m         hallucinated_examples, features_to_look_at, k\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m\n\u001b[1;32m     62\u001b[0m     )\n",
      "Cell \u001b[0;32mIn[30], line 18\u001b[0m, in \u001b[0;36m_get_feature_acts_for_sample_class\u001b[0;34m(sample_class, features_to_use_for_classification, k, batch_size)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_feature_acts_for_sample_class\u001b[39m(\n\u001b[1;32m     12\u001b[0m     sample_class: pd\u001b[38;5;241m.\u001b[39mDataFrame,\n\u001b[1;32m     13\u001b[0m     features_to_use_for_classification: gf\u001b[38;5;241m.\u001b[39mFeatureGroup,\n\u001b[1;32m     14\u001b[0m     k\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m,\n\u001b[1;32m     15\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m\n\u001b[1;32m     16\u001b[0m ):\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mlen\u001b[39m(features_to_use_for_classification):\n\u001b[0;32m---> 18\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m     19\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mk must be greater than the number of features to use for classification\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     20\u001b[0m         )\n\u001b[1;32m     22\u001b[0m     samples \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     23\u001b[0m     all_samples \u001b[38;5;241m=\u001b[39m sample_class[\u001b[38;5;241m0\u001b[39m:MIN_SAMPLES_PER_CLASS]\n",
      "\u001b[0;31mValueError\u001b[0m: k must be greater than the number of features to use for classification"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import asyncio\n",
    "from tqdm.asyncio import tqdm_asyncio\n",
    "\n",
    "\n",
    "MIN_SAMPLES_PER_CLASS = min(\n",
    "    len(hallucinated_examples),\n",
    "    len(truthful_examples),\n",
    ")\n",
    "\n",
    "async def _get_feature_acts_for_sample_class(\n",
    "    sample_class: pd.DataFrame,\n",
    "    features_to_use_for_classification: gf.FeatureGroup,\n",
    "    k=50,\n",
    "    batch_size=100\n",
    "):\n",
    "    if k < len(features_to_use_for_classification):\n",
    "        raise ValueError(\n",
    "            \"k must be greater than the number of features to use for classification\"\n",
    "        )\n",
    "\n",
    "    samples = []\n",
    "    all_samples = sample_class[0:MIN_SAMPLES_PER_CLASS]\n",
    "\n",
    "    # Process in batches\n",
    "    for i in range(0, len(all_samples), batch_size):\n",
    "        batch = all_samples[i:i + batch_size]\n",
    "        tasks = []\n",
    "\n",
    "        for idx, row in batch.iterrows():\n",
    "            prompt = row[\"prompt\"]\n",
    "            tasks.append(\n",
    "                async_client.features.inspect(\n",
    "                    [\n",
    "                        {\n",
    "                            \"role\": \"user\",\n",
    "                            \"content\": f\"{prompt}\",\n",
    "                        }\n",
    "                    ],\n",
    "                    model=variant,\n",
    "                    features=features_to_use_for_classification,\n",
    "                )\n",
    "            )\n",
    "\n",
    "        # Process this batch\n",
    "        batch_results = await tqdm_asyncio.gather(*tasks)\n",
    "        for context in batch_results:\n",
    "            features = context.top(k=k)\n",
    "            samples.append(features)\n",
    "\n",
    "    return samples\n",
    "\n",
    "async def process_all_classes():\n",
    "    print(\"Computing truthful features...\")\n",
    "    truthful_class_features = await _get_feature_acts_for_sample_class(\n",
    "        truthful_examples, features_to_look_at, k=50\n",
    "    )\n",
    "\n",
    "    print(\"Computing hallucinated features...\")\n",
    "    hallucinated_class_features = await _get_feature_acts_for_sample_class(\n",
    "        hallucinated_examples, features_to_look_at, k=50\n",
    "    )\n",
    "\n",
    "\n",
    "    return truthful_class_features, hallucinated_class_features\n",
    "\n",
    "truthful_class_features, hallucinated_class_features = await process_all_classes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 100)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(truthful_class_features[0]), len(hallucinated_class_features[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Save the data to a file\n",
    "def save_feature_activations(name: str, feature_activations):\n",
    "  with open(f\"../data/{name}.pkl\", \"wb\") as f:\n",
    "      pickle.dump(feature_activations, f)\n",
    "\n",
    "\n",
    "save_feature_activations(\"truthful_class_features\", truthful_class_features)\n",
    "save_feature_activations(\"hallucinated_class_features\", hallucinated_class_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "# Load the data from a file\n",
    "def load_feature_activations(name: str):\n",
    "  with open(f\"../data/{name}.pkl\", \"rb\") as f:\n",
    "      activations = pickle.load(f)\n",
    "  return activations\n",
    "\n",
    "truthful_class_features = load_feature_activations('truthful_class_features')\n",
    "hallucinated_class_features = load_feature_activations('hallucinated_class_features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import balanced_accuracy_score, accuracy_score, f1_score\n",
    "import numpy as np\n",
    "import tqdm\n",
    "\n",
    "\n",
    "# Grid search may take a while, you can curate the feature list to speed this process up significantly\n",
    "\n",
    "def train_tree(x, y, depth):\n",
    "  train_x, test_x, train_y, test_y = train_test_split(\n",
    "    x, y, train_size=0.5, random_state=42)\n",
    "\n",
    "  # Create a nice regularized tree\n",
    "  model = DecisionTreeClassifier(\n",
    "    max_depth=depth,\n",
    "    min_samples_leaf=len(train_x) // 10,\n",
    "    random_state=42\n",
    "  )\n",
    "\n",
    "  model.fit(train_x, train_y)\n",
    "\n",
    "  pred = model.predict(test_x)\n",
    "\n",
    "  # Calculate the f1 score of the model\n",
    "  accuracy = balanced_accuracy_score(test_y, pred)\n",
    "  score = f1_score(test_y, pred)\n",
    "\n",
    "  return model, pred, score,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_combo(features, k_features_per_combo=2):\n",
    "    combos = FeatureSearch(features).grid(k_features_per_combo=k_features_per_combo)\n",
    "    best_combo = None\n",
    "    best_model = None\n",
    "    mean_act_negative = 0\n",
    "    mean_act_positive = 0\n",
    "    support_vector_distances = 0\n",
    "    best_score = 0\n",
    "\n",
    "    for combo in tqdm.tqdm(combos):\n",
    "        # Create a linear regression model\n",
    "        def _select_feature_acts(combo, row):\n",
    "            output = []\n",
    "            for index, feature in enumerate(combo):\n",
    "                for feature_act in row:\n",
    "                    if feature_act.feature.uuid == feature.uuid:\n",
    "                        output.append(feature_act.activation)\n",
    "                        break\n",
    "\n",
    "            return output\n",
    "\n",
    "        x_hallucinated = [\n",
    "            _select_feature_acts(combo, row) for row in hallucinated_class_features\n",
    "        ]\n",
    "        x_truthful = [\n",
    "            _select_feature_acts(combo, row) for row in truthful_class_features\n",
    "        ]\n",
    "\n",
    "        y_hallucinated = [-1] * len(x_hallucinated)\n",
    "        y_truthful = [1] * len(x_truthful)\n",
    "\n",
    "        x = x_hallucinated + x_truthful\n",
    "        y = y_truthful + y_hallucinated\n",
    "\n",
    "        model, pred, score = train_tree(x, y, depth=len(combo))\n",
    "\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_combo = combo\n",
    "            best_model = model\n",
    "\n",
    "    return best_combo, best_score, best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:00<00:00, 212.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 (Feature(\"Lymphatic system terminology in medical contexts\"),) 0.6861313868613139 DecisionTreeClassifier(max_depth=1, min_samples_leaf=10, random_state=42)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4950/4950 [00:28<00:00, 174.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 (Feature(\"Medical devices and prosthetics, particularly their mechanical structure and operation\"), Feature(\"Multiple choice answer options evaluating truth values of statements\")) 0.7142857142857143 DecisionTreeClassifier(max_depth=2, min_samples_leaf=10, random_state=42)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 161700/161700 [18:21<00:00, 146.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 (Feature(\"Medical descriptions of pain and physical discomfort\"), Feature(\"Medical discussions of pregnancy complications and risks\"), Feature(\"Lymphatic system terminology in medical contexts\")) 0.7213114754098361 DecisionTreeClassifier(max_depth=3, min_samples_leaf=10, random_state=42)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▊        | 730851/3921225 [1:37:32<7:05:47, 124.88it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m best_combo_at_k \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m4\u001b[39m):\n\u001b[0;32m----> 4\u001b[0m     best_combo, best_score, best_model \u001b[38;5;241m=\u001b[39m \u001b[43mfind_best_combo\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m      \u001b[49m\u001b[43mfeatures_to_look_at\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk_features_per_combo\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\n\u001b[1;32m      6\u001b[0m \u001b[43m      \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28mprint\u001b[39m(i \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m, best_combo, best_score, best_model)\n\u001b[1;32m      8\u001b[0m     best_combo_at_k[i \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m=\u001b[39m (best_combo, best_score, best_model)\n",
      "Cell \u001b[0;32mIn[20], line 22\u001b[0m, in \u001b[0;36mfind_best_combo\u001b[0;34m(features, k_features_per_combo)\u001b[0m\n\u001b[1;32m     18\u001b[0m                 \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output\n\u001b[0;32m---> 22\u001b[0m x_hallucinated \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_select_feature_acts\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcombo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrow\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrow\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mhallucinated_class_features\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[43m\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     25\u001b[0m x_truthful \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     26\u001b[0m     _select_feature_acts(combo, row) \u001b[38;5;28;01mfor\u001b[39;00m row \u001b[38;5;129;01min\u001b[39;00m truthful_class_features\n\u001b[1;32m     27\u001b[0m ]\n\u001b[1;32m     29\u001b[0m y_hallucinated \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mlen\u001b[39m(x_hallucinated)\n",
      "Cell \u001b[0;32mIn[20], line 23\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     18\u001b[0m                 \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output\n\u001b[1;32m     22\u001b[0m x_hallucinated \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m---> 23\u001b[0m     \u001b[43m_select_feature_acts\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcombo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrow\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m row \u001b[38;5;129;01min\u001b[39;00m hallucinated_class_features\n\u001b[1;32m     24\u001b[0m ]\n\u001b[1;32m     25\u001b[0m x_truthful \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     26\u001b[0m     _select_feature_acts(combo, row) \u001b[38;5;28;01mfor\u001b[39;00m row \u001b[38;5;129;01min\u001b[39;00m truthful_class_features\n\u001b[1;32m     27\u001b[0m ]\n\u001b[1;32m     29\u001b[0m y_hallucinated \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mlen\u001b[39m(x_hallucinated)\n",
      "Cell \u001b[0;32mIn[20], line 16\u001b[0m, in \u001b[0;36mfind_best_combo.<locals>._select_feature_acts\u001b[0;34m(combo, row)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m index, feature \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(combo):\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m feature_act \u001b[38;5;129;01min\u001b[39;00m row:\n\u001b[0;32m---> 16\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mfeature_act\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43muuid\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mfeature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43muuid\u001b[49m:\n\u001b[1;32m     17\u001b[0m             output\u001b[38;5;241m.\u001b[39mappend(feature_act\u001b[38;5;241m.\u001b[39mactivation)\n\u001b[1;32m     18\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/uuid.py:240\u001b[0m, in \u001b[0;36mUUID.__eq__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    235\u001b[0m     \u001b[38;5;66;03m# is_safe was added in 3.7; it is also omitted when it is \"unknown\"\u001b[39;00m\n\u001b[1;32m    236\u001b[0m     \u001b[38;5;28mobject\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__setattr__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mis_safe\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m    237\u001b[0m                        SafeUUID(state[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mis_safe\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m    238\u001b[0m                        \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mis_safe\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m state \u001b[38;5;28;01melse\u001b[39;00m SafeUUID\u001b[38;5;241m.\u001b[39munknown)\n\u001b[0;32m--> 240\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__eq__\u001b[39m(\u001b[38;5;28mself\u001b[39m, other):\n\u001b[1;32m    241\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(other, UUID):\n\u001b[1;32m    242\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mint \u001b[38;5;241m==\u001b[39m other\u001b[38;5;241m.\u001b[39mint\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "best_combo_at_k = {}\n",
    "\n",
    "for i in range(4):\n",
    "    best_combo, best_score, best_model = find_best_combo(\n",
    "      features_to_look_at, k_features_per_combo = i + 1\n",
    "      )\n",
    "    print(i + 1, best_combo, best_score, best_model)\n",
    "    best_combo_at_k[i + 1] = (best_combo, best_score, best_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k=1 features: score=0.6861313868613139\n",
      "k=2 features: score=0.7207207207207207\n",
      "k=3 features: score=0.7213114754098361\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Feature(\"Medical descriptions of pain and physical discomfort\")"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for k in [1, 2, 3, 4]:\n",
    "    combo, score, model = best_combo_at_k[k]\n",
    "    print(f\"k={k} features: score={score}\")\n",
    "    \n",
    "best_individual_feature = best_combo_at_k[3][0][0]\n",
    "best_individual_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'best_individual_feature' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m feature_grp \u001b[38;5;241m=\u001b[39m client\u001b[38;5;241m.\u001b[39mfeatures\u001b[38;5;241m.\u001b[39mneighbors(\u001b[43mbest_individual_feature\u001b[49m, model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmeta-llama/Meta-Llama-3.1-8B-Instruct\u001b[39m\u001b[38;5;124m\"\u001b[39m )\n\u001b[1;32m      2\u001b[0m feature_grp\n",
      "\u001b[0;31mNameError\u001b[0m: name 'best_individual_feature' is not defined"
     ]
    }
   ],
   "source": [
    "feature_grp = client.features.neighbors(best_individual_feature, model=\"meta-llama/Meta-Llama-3.1-8B-Instruct\" )\n",
    "feature_grp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((Feature(\"Medical descriptions of pain and physical discomfort\"),\n",
       "  Feature(\"Medical discussions of pregnancy complications and risks\"),\n",
       "  Feature(\"Lymphatic system terminology in medical contexts\")),\n",
       " DecisionTreeClassifier(max_depth=3, min_samples_leaf=10, random_state=42))"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Anyways let's look at the best overall tree\n",
    "\n",
    "BEST_TREE_INDEX = 3\n",
    "best_features = best_combo_at_k[BEST_TREE_INDEX][0]\n",
    "best_tree = best_combo_at_k[BEST_TREE_INDEX][2]\n",
    "\n",
    "best_features, best_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 12.2.0 (20241103.1931)\n",
       " -->\n",
       "<!-- Title: Tree Pages: 1 -->\n",
       "<svg width=\"650pt\" height=\"433pt\"\n",
       " viewBox=\"0.00 0.00 650.00 433.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 429)\">\n",
       "<title>Tree</title>\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-429 646,-429 646,4 -4,4\"/>\n",
       "<!-- 0 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>0</title>\n",
       "<path fill=\"#fefaf7\" stroke=\"black\" d=\"M628.5,-425C628.5,-425 299.75,-425 299.75,-425 293.75,-425 287.75,-419 287.75,-413 287.75,-413 287.75,-354 287.75,-354 287.75,-348 293.75,-342 299.75,-342 299.75,-342 628.5,-342 628.5,-342 634.5,-342 640.5,-348 640.5,-354 640.5,-354 640.5,-413 640.5,-413 640.5,-419 634.5,-425 628.5,-425\"/>\n",
       "<text text-anchor=\"start\" x=\"295.75\" y=\"-407.7\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Lymphatic system terminology in medical contexts ≤ 0.5</text>\n",
       "<text text-anchor=\"start\" x=\"436.38\" y=\"-392.7\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.5</text>\n",
       "<text text-anchor=\"start\" x=\"419.5\" y=\"-377.7\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 100</text>\n",
       "<text text-anchor=\"start\" x=\"417.62\" y=\"-362.7\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [51, 49]</text>\n",
       "<text text-anchor=\"start\" x=\"420.25\" y=\"-347.7\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = truthful</text>\n",
       "</g>\n",
       "<!-- 1 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>1</title>\n",
       "<path fill=\"#d9ecfa\" stroke=\"black\" d=\"M508.38,-306C508.38,-306 169.88,-306 169.88,-306 163.88,-306 157.88,-300 157.88,-294 157.88,-294 157.88,-235 157.88,-235 157.88,-229 163.88,-223 169.88,-223 169.88,-223 508.38,-223 508.38,-223 514.38,-223 520.38,-229 520.38,-235 520.38,-235 520.38,-294 520.38,-294 520.38,-300 514.38,-306 508.38,-306\"/>\n",
       "<text text-anchor=\"start\" x=\"165.88\" y=\"-288.7\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Medical descriptions of pain and physical discomfort ≤ 3.5</text>\n",
       "<text text-anchor=\"start\" x=\"303.88\" y=\"-273.7\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.494</text>\n",
       "<text text-anchor=\"start\" x=\"298.25\" y=\"-258.7\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 85</text>\n",
       "<text text-anchor=\"start\" x=\"292.62\" y=\"-243.7\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [38, 47]</text>\n",
       "<text text-anchor=\"start\" x=\"279.88\" y=\"-228.7\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = hallucinated</text>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;1 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>0&#45;&gt;1</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M420.41,-341.58C410.84,-332.62 400.62,-323.06 390.77,-313.84\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"393.41,-311.51 383.71,-307.23 388.62,-316.62 393.41,-311.51\"/>\n",
       "<text text-anchor=\"middle\" x=\"383.43\" y=\"-325.39\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">True</text>\n",
       "</g>\n",
       "<!-- 6 -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>6</title>\n",
       "<path fill=\"#e99457\" stroke=\"black\" d=\"M630,-298.5C630,-298.5 550.25,-298.5 550.25,-298.5 544.25,-298.5 538.25,-292.5 538.25,-286.5 538.25,-286.5 538.25,-242.5 538.25,-242.5 538.25,-236.5 544.25,-230.5 550.25,-230.5 550.25,-230.5 630,-230.5 630,-230.5 636,-230.5 642,-236.5 642,-242.5 642,-242.5 642,-286.5 642,-286.5 642,-292.5 636,-298.5 630,-298.5\"/>\n",
       "<text text-anchor=\"start\" x=\"554.88\" y=\"-281.2\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.231</text>\n",
       "<text text-anchor=\"start\" x=\"549.25\" y=\"-266.2\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 15</text>\n",
       "<text text-anchor=\"start\" x=\"547.38\" y=\"-251.2\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [13, 2]</text>\n",
       "<text text-anchor=\"start\" x=\"546.25\" y=\"-236.2\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = truthful</text>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;6 -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>0&#45;&gt;6</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M508.19,-341.58C520.42,-330.23 533.69,-317.9 545.92,-306.55\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"548.14,-309.26 553.09,-299.89 543.38,-304.13 548.14,-309.26\"/>\n",
       "<text text-anchor=\"middle\" x=\"553.27\" y=\"-318.04\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">False</text>\n",
       "</g>\n",
       "<!-- 2 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>2</title>\n",
       "<path fill=\"#ebf5fc\" stroke=\"black\" d=\"M384.25,-187C384.25,-187 12,-187 12,-187 6,-187 0,-181 0,-175 0,-175 0,-116 0,-116 0,-110 6,-104 12,-104 12,-104 384.25,-104 384.25,-104 390.25,-104 396.25,-110 396.25,-116 396.25,-116 396.25,-175 396.25,-175 396.25,-181 390.25,-187 384.25,-187\"/>\n",
       "<text text-anchor=\"start\" x=\"8\" y=\"-169.7\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Medical discussions of pregnancy complications and risks ≤ 0.5</text>\n",
       "<text text-anchor=\"start\" x=\"162.88\" y=\"-154.7\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.499</text>\n",
       "<text text-anchor=\"start\" x=\"157.25\" y=\"-139.7\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 74</text>\n",
       "<text text-anchor=\"start\" x=\"140.38\" y=\"-124.7\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [35.0, 39.0]</text>\n",
       "<text text-anchor=\"start\" x=\"138.88\" y=\"-109.7\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = hallucinated</text>\n",
       "</g>\n",
       "<!-- 1&#45;&gt;2 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>1&#45;&gt;2</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M289.81,-222.58C278.8,-213.44 267.03,-203.67 255.71,-194.29\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"258.27,-191.86 248.34,-188.17 253.8,-197.25 258.27,-191.86\"/>\n",
       "</g>\n",
       "<!-- 5 -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>5</title>\n",
       "<path fill=\"#83c2ef\" stroke=\"black\" d=\"M536.38,-179.5C536.38,-179.5 425.88,-179.5 425.88,-179.5 419.88,-179.5 413.88,-173.5 413.88,-167.5 413.88,-167.5 413.88,-123.5 413.88,-123.5 413.88,-117.5 419.88,-111.5 425.88,-111.5 425.88,-111.5 536.38,-111.5 536.38,-111.5 542.38,-111.5 548.38,-117.5 548.38,-123.5 548.38,-123.5 548.38,-167.5 548.38,-167.5 548.38,-173.5 542.38,-179.5 536.38,-179.5\"/>\n",
       "<text text-anchor=\"start\" x=\"445.88\" y=\"-162.2\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.397</text>\n",
       "<text text-anchor=\"start\" x=\"440.25\" y=\"-147.2\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 11</text>\n",
       "<text text-anchor=\"start\" x=\"442.12\" y=\"-132.2\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [3, 8]</text>\n",
       "<text text-anchor=\"start\" x=\"421.88\" y=\"-117.2\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = hallucinated</text>\n",
       "</g>\n",
       "<!-- 1&#45;&gt;5 -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>1&#45;&gt;5</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M388.79,-222.58C402.83,-211.01 418.1,-198.43 432.1,-186.89\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"433.98,-189.88 439.47,-180.82 429.52,-184.48 433.98,-189.88\"/>\n",
       "</g>\n",
       "<!-- 3 -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>3</title>\n",
       "<path fill=\"#d7ebfa\" stroke=\"black\" d=\"M185.38,-68C185.38,-68 74.88,-68 74.88,-68 68.88,-68 62.88,-62 62.88,-56 62.88,-56 62.88,-12 62.88,-12 62.88,-6 68.88,0 74.88,0 74.88,0 185.38,0 185.38,0 191.38,0 197.38,-6 197.38,-12 197.38,-12 197.38,-56 197.38,-56 197.38,-62 191.38,-68 185.38,-68\"/>\n",
       "<text text-anchor=\"start\" x=\"94.88\" y=\"-50.7\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.494</text>\n",
       "<text text-anchor=\"start\" x=\"89.25\" y=\"-35.7\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 63</text>\n",
       "<text text-anchor=\"start\" x=\"83.62\" y=\"-20.7\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [28, 35]</text>\n",
       "<text text-anchor=\"start\" x=\"70.88\" y=\"-5.7\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = hallucinated</text>\n",
       "</g>\n",
       "<!-- 2&#45;&gt;3 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>2&#45;&gt;3</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M172.8,-103.73C167.59,-95.34 162.09,-86.47 156.83,-78.01\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"159.85,-76.23 151.6,-69.59 153.9,-79.93 159.85,-76.23\"/>\n",
       "</g>\n",
       "<!-- 4 -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>4</title>\n",
       "<path fill=\"#f4c9aa\" stroke=\"black\" d=\"M307,-68C307,-68 227.25,-68 227.25,-68 221.25,-68 215.25,-62 215.25,-56 215.25,-56 215.25,-12 215.25,-12 215.25,-6 221.25,0 227.25,0 227.25,0 307,0 307,0 313,0 319,-6 319,-12 319,-12 319,-56 319,-56 319,-62 313,-68 307,-68\"/>\n",
       "<text text-anchor=\"start\" x=\"231.88\" y=\"-50.7\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.463</text>\n",
       "<text text-anchor=\"start\" x=\"226.25\" y=\"-35.7\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 11</text>\n",
       "<text text-anchor=\"start\" x=\"228.12\" y=\"-20.7\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [7, 4]</text>\n",
       "<text text-anchor=\"start\" x=\"223.25\" y=\"-5.7\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = truthful</text>\n",
       "</g>\n",
       "<!-- 2&#45;&gt;4 -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>2&#45;&gt;4</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M223.82,-103.73C229.11,-95.34 234.69,-86.47 240.02,-78.01\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"242.96,-79.91 245.33,-69.58 237.04,-76.17 242.96,-79.91\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.sources.Source at 0x16074c1d0>"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's visualize the tree\n",
    "from sklearn.tree import export_graphviz\n",
    "import graphviz\n",
    "\n",
    "dot_data = export_graphviz(\n",
    "  best_tree, \n",
    "  out_file=None, \n",
    "  feature_names=[feature.label for feature in best_features], \n",
    "  class_names=['truthful', 'hallucinated'], \n",
    "  filled=True, \n",
    "  rounded=True, \n",
    "  special_characters=True\n",
    "  )\n",
    "graph = graphviz.Source(dot_data)\n",
    "graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import tqdm\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "def run_in_thread(func, *args, **kwargs):\n",
    "    loop = asyncio.new_event_loop()\n",
    "    asyncio.set_event_loop(loop)\n",
    "\n",
    "    # Call the function directly if it's not async\n",
    "    result = func(*args, **kwargs)\n",
    "\n",
    "    loop.close()\n",
    "    return result\n",
    "\n",
    "def get_feature_activations(client, variant, examples, features, k=50):\n",
    "    \"\"\"\n",
    "    Get feature activations for a set of examples using Goodfire with run_in_thread\n",
    "    \"\"\"\n",
    "    samples = []\n",
    "\n",
    "    with ThreadPoolExecutor(max_workers=3) as executor:\n",
    "        futures_list = []\n",
    "\n",
    "        for example in examples:\n",
    "            futures_list.append(\n",
    "                executor.submit(\n",
    "                    run_in_thread,\n",
    "                    client.features.inspect,  # Async function\n",
    "                    example,\n",
    "                    model=variant,\n",
    "                    features=features,\n",
    "                )\n",
    "            )\n",
    "\n",
    "        for future in tqdm.tqdm(futures_list, desc=\"Fetching Features\"):\n",
    "            context = future.result()\n",
    "            features = context.top(k=k)\n",
    "            samples.append(features)\n",
    "\n",
    "    return samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'role': 'user',\n",
       "   'content': 'You are a medical expert and this is a multiple choice exam question. Please respond with the integer index of the CORRECT answer only; [0,1,2,3].\\n\\nPrognosis of treatment in case of Class II malocclusion is favorable when?\\n\\nOptions: {\"0\": \"Class II malocclusion without sliding of mandible\", \"1\": \"Class II malocclusion with anterior sliding of mandible\", \"2\": \"Class II malocclusion with posterior sliding of mandible\", \"3\": \"Prognosis does not depend on sliding of mandible\"}'},\n",
       "  {'role': 'assistant', 'content': '3'}]]"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_1[0:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching Features: 100%|██████████| 1/1 [00:02<00:00,  2.61s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[FeatureActivations(\n",
       "    0: (Feature(\"Lymphatic system terminology in medical contexts\"), 0)\n",
       "    1: (Feature(\"Medical discussions of pregnancy complications and risks\"), 0)\n",
       "    2: (Feature(\"Medical descriptions of pain and physical discomfort\"), 0)\n",
       "    3: (Feature(\"Variable assignments and value retrievals in calculator code\"), 0)\n",
       "    4: (Feature(\"Birth dates in biographical/historical contexts\"), 0)\n",
       "    5: (Feature(\"Syntactical elements in programming code and database queries\"), 0)\n",
       "    6: (Feature(\"Discussion of limited or scarce resources and constraints\"), 0)\n",
       "    7: (Feature(\"Syntactical special characters and delimiters in programming contexts\"), 0)\n",
       "    8: (Feature(\"feature_0\"), 0)\n",
       "    9: (Feature(\"The Russian word состав (composition/compilation) and its variations\"), 0)\n",
       "    ...\n",
       "    22: (Feature(\"Technical documentation describing widespread applications and uses\"), 0)\n",
       " )]"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_activations = get_feature_activations(client, variant, dataset_1[0:1], best_features)\n",
    "example_activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import goodfire as gf\n",
    "from typing import List, Dict, Tuple, Any\n",
    "import numpy as np\n",
    "\n",
    "class HallucinationClassifier:\n",
    "    def __init__(self, model_path: str, api_key: str):\n",
    "        \"\"\"\n",
    "        Initialize the hallucination classifier with a saved model and features.\n",
    "        \n",
    "        Args:\n",
    "            model_path: Path to the saved pickle file containing both the model and features\n",
    "            api_key: Goodfire API key for accessing the service\n",
    "        \"\"\"\n",
    "        # Load the model and features\n",
    "        with open(model_path, 'rb') as f:\n",
    "            model_data = pickle.load(f)\n",
    "            self.model = model_data['model']\n",
    "            self.features = model_data['features']\n",
    "        self.client = gf.Client(api_key)\n",
    "        self.variant = gf.Variant(\"meta-llama/Meta-Llama-3.1-8B-Instruct\")\n",
    "\n",
    "    def _format_prompt(self, question: str) -> List[Dict[str, str]]:\n",
    "        \"\"\"Format a question into the expected prompt structure.\"\"\"\n",
    "        introduction = (\"You are a medical expert and this is a multiple choice exam question. \"\n",
    "                      \"Please respond with the integer index of the CORRECT answer only; [0,1,2,3].\")\n",
    "        return [{\"role\": \"user\", \"content\": f\"{introduction}\\n\\n{question}\"}]\n",
    "      \n",
    "\n",
    "    def _get_feature_activations(self, prompt: List[Dict[str, str]]) -> List[float]:\n",
    "        \"\"\"Get feature activations for the input prompt.\"\"\"\n",
    "        context = self.client.features.inspect(\n",
    "            message=prompt,\n",
    "            model=self.variant,\n",
    "            features=self.features\n",
    "        )\n",
    "        \n",
    "        # Get activations for our specific features\n",
    "        activations = []\n",
    "        features_dict = {f.uuid: 0.0 for f in self.features}\n",
    "        \n",
    "        for feature_act in context.top(k=len(self.features)):\n",
    "            if feature_act.feature.uuid in features_dict:\n",
    "                features_dict[feature_act.feature.uuid] = feature_act.activation\n",
    "        \n",
    "        # Maintain order matching the original features\n",
    "        for feature in self.features:\n",
    "            activations.append(features_dict[feature.uuid])\n",
    "            \n",
    "        return activations\n",
    "\n",
    "    def predict(self, question: str, debug: bool = False) -> Tuple[int, float]:\n",
    "        \"\"\"\n",
    "        Predict whether a given question-answer pair is likely to contain hallucination.\n",
    "        \n",
    "        Args:\n",
    "            question: The question text\n",
    "            debug: If True, print debugging information about feature activations\n",
    "            \n",
    "        Returns:\n",
    "            Tuple containing:\n",
    "            - Prediction (0 for truthful, 1 for hallucinated)\n",
    "            - Confidence score (probability of the predicted class)\n",
    "        \"\"\"\n",
    "        # Format the prompt\n",
    "        prompt = self._format_prompt(question)\n",
    "        \n",
    "        # Get feature activations\n",
    "        activations = self._get_feature_activations(prompt)\n",
    "        \n",
    "        if debug:\n",
    "            print(\"\\nFeature Activations:\")\n",
    "            for feature, activation in zip(self.features, activations):\n",
    "                print(f\"{feature.label}: {activation:.4f}\")\n",
    "            \n",
    "            # Get the decision path\n",
    "            decision_path = self.model.decision_path([activations])\n",
    "            feature_importance = self.model.feature_importances_\n",
    "            \n",
    "            print(\"\\nFeature Importance in Model:\")\n",
    "            for feature, importance in zip(self.features, feature_importance):\n",
    "                print(f\"{feature.label}: {importance:.4f}\")\n",
    "            \n",
    "            print(\"\\nDecision Path:\")\n",
    "            node_indicator = decision_path[0]\n",
    "            leaf_id = self.model.apply([activations])[0]\n",
    "            \n",
    "            # Get thresholds and feature indices for each node in path\n",
    "            for node_id in node_indicator.indices:\n",
    "                if node_id != leaf_id:\n",
    "                    feature_idx = self.model.tree_.feature[node_id]\n",
    "                    threshold = self.model.tree_.threshold[node_id]\n",
    "                    feature_name = self.features[feature_idx].label\n",
    "                    feature_value = activations[feature_idx]\n",
    "                    print(f\"Node {node_id}: {feature_name} = {feature_value:.4f} {'<=' if feature_value <= threshold else '>'} {threshold:.4f}\")\n",
    "        \n",
    "        # Make prediction\n",
    "        prediction = self.model.predict([activations])[0]\n",
    "        probabilities = self.model.predict_proba([activations])[0]\n",
    "        confidence = probabilities[prediction]\n",
    "        \n",
    "        if debug:\n",
    "            print(f\"\\nProbabilities:\")\n",
    "            print(f\"Truthful: {probabilities[0]:.4f}\")\n",
    "            print(f\"Hallucinated: {probabilities[1]:.4f}\")\n",
    "        \n",
    "        return int(prediction), float(confidence)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model_and_features(model, features, output_path: str):\n",
    "    \"\"\"Save both the sklearn decision tree model and Goodfire features to a file.\n",
    "    \n",
    "    Args:\n",
    "        model: The trained sklearn decision tree model\n",
    "        features: The Goodfire features used by the model\n",
    "        output_path: Path where to save the pickle file\n",
    "    \"\"\"\n",
    "    model_data = {\n",
    "        'model': model,\n",
    "        'features': features\n",
    "    }\n",
    "    with open(output_path, 'wb') as f:\n",
    "        pickle.dump(model_data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model and best_features\n",
    "\n",
    "model_path = \"hallucination_model.pkl\"\n",
    "save_model_and_features(best_tree, best_features, model_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the classifier (now simpler, no need to pass features separately)\n",
    "classifier = HallucinationClassifier(\n",
    "    model_path=model_path,\n",
    "    api_key=api_key\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are a medical expert and this is a multiple choice exam question. Please respond with the integer index of the CORRECT answer only; [0,1,2,3].\n",
      "\n",
      "Which of the following type of leukaemia has a maximum tendency of gingival enlargement:\n",
      "\n",
      "Options: {\"0\": \"Acute monocytic leukaemia.\", \"1\": \"Acute myelocytic leukaemia.\", \"2\": \"Acute myelocytic monocytic leukaemia.\", \"3\": \"None.\"}\n",
      "\n",
      "Feature Activations:\n",
      "Referential continuity through pronouns and articles in narrative flow: 3.0000\n",
      "Medical symptom descriptions and disease progression patterns: 13.0000\n",
      "Lymphatic system terminology in medical contexts: 4.0000\n",
      "\n",
      "Feature Importance in Model:\n",
      "Referential continuity through pronouns and articles in narrative flow: 0.2356\n",
      "Medical symptom descriptions and disease progression patterns: 0.1496\n",
      "Lymphatic system terminology in medical contexts: 0.6147\n",
      "\n",
      "Decision Path:\n",
      "Node 0: Lymphatic system terminology in medical contexts = 4.0000 > 0.5000\n",
      "Node 8: Referential continuity through pronouns and articles in narrative flow = 3.0000 <= 5.5000\n",
      "\n",
      "Probabilities:\n",
      "Truthful: 1.0000\n",
      "Hallucinated: 0.0000\n",
      "Prediction:  -1\n",
      "Prediction: Truthful\n",
      "Confidence: 0.00\n"
     ]
    }
   ],
   "source": [
    "# Make predictions - Example from truthful dataframe\n",
    "\n",
    "prompt_example = truthful_examples.iloc[20]['prompt']\n",
    "print(prompt_example)\n",
    "\n",
    "prediction, confidence = classifier.predict(prompt_example,debug=True)\n",
    "print(\"Prediction: \", prediction)\n",
    "print(f\"Prediction: {'Hallucinated' if prediction == 1 else 'Truthful'}\")\n",
    "print(f\"Confidence: {confidence:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EVALUATION ON TRAIN & TEST DATASETS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "def evaluate_model_predictions(classifier, truthful_examples, hallucinated_examples):\n",
    "    \"\"\"\n",
    "    Evaluate model predictions across all examples.\n",
    "    \n",
    "    Args:\n",
    "        classifier: The HallucinationClassifier instance\n",
    "        truthful_examples: DataFrame containing truthful examples\n",
    "        hallucinated_examples: DataFrame containing hallucinated examples\n",
    "    \"\"\"\n",
    "    # Store results\n",
    "    results = []\n",
    "    \n",
    "    # Process truthful examples\n",
    "    print(\"\\nProcessing truthful examples...\")\n",
    "    for idx, row in tqdm(truthful_examples.iterrows(), total=len(truthful_examples)):\n",
    "        prediction, confidence = classifier.predict(row['prompt'])\n",
    "        results.append({\n",
    "            'true_label': 'truthful',\n",
    "            'predicted': 'hallucinated' if prediction == 1 else 'truthful',\n",
    "            'confidence': confidence\n",
    "        })\n",
    "    \n",
    "    # Process hallucinated examples\n",
    "    print(\"\\nProcessing hallucinated examples...\")\n",
    "    for idx, row in tqdm(hallucinated_examples.iterrows(), total=len(hallucinated_examples)):\n",
    "        prediction, confidence = classifier.predict(row['prompt'])\n",
    "        results.append({\n",
    "            'true_label': 'hallucinated',\n",
    "            'predicted': 'hallucinated' if prediction == 1 else 'truthful',\n",
    "            'confidence': confidence\n",
    "        })\n",
    "    \n",
    "    # Convert to DataFrame for analysis\n",
    "    results_df = pd.DataFrame(results)\n",
    "    \n",
    "    # Calculate overall statistics\n",
    "    total_predictions = len(results_df)\n",
    "    print(\"\\nOverall Statistics:\")\n",
    "    print(f\"Total examples evaluated: {total_predictions}\")\n",
    "    \n",
    "    # Prediction distribution\n",
    "    pred_dist = results_df['predicted'].value_counts()\n",
    "    print(\"\\nPrediction Distribution:\")\n",
    "    for pred, count in pred_dist.items():\n",
    "        percentage = (count/total_predictions) * 100\n",
    "        print(f\"{pred}: {count} ({percentage:.1f}%)\")\n",
    "    \n",
    "    # Confusion Matrix\n",
    "    print(\"\\nConfusion Matrix:\")\n",
    "    confusion = pd.crosstab(results_df['true_label'], results_df['predicted'])\n",
    "    print(confusion)\n",
    "    \n",
    "    # Calculate metrics by class\n",
    "    print(\"\\nMetrics by True Label:\")\n",
    "    for label in ['truthful', 'hallucinated']:\n",
    "        class_results = results_df[results_df['true_label'] == label]\n",
    "        correct = (class_results['true_label'] == class_results['predicted']).sum()\n",
    "        total = len(class_results)\n",
    "        accuracy = (correct/total) * 100\n",
    "        avg_confidence = class_results['confidence'].mean()\n",
    "        \n",
    "        print(f\"\\n{label.title()} Examples:\")\n",
    "        print(f\"Accuracy: {accuracy:.1f}%\")\n",
    "        print(f\"Average Confidence: {avg_confidence:.3f}\")\n",
    "    \n",
    "    # Return the results DataFrame for further analysis if needed\n",
    "    return results_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TRAIN DATASET EVALUATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, hallucinated_examples_test = prepare_dataset(val_data, hallucinated=True)\n",
    "_, truthful_examples_test = prepare_dataset(val_data, hallucinated=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing truthful examples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:00<00:00,  2.42s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing hallucinated examples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:58<00:00,  2.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Overall Statistics:\n",
      "Total examples evaluated: 50\n",
      "\n",
      "Prediction Distribution:\n",
      "hallucinated: 37 (74.0%)\n",
      "truthful: 13 (26.0%)\n",
      "\n",
      "Confusion Matrix:\n",
      "predicted     hallucinated  truthful\n",
      "true_label                          \n",
      "hallucinated            19         6\n",
      "truthful                18         7\n",
      "\n",
      "Metrics by True Label:\n",
      "\n",
      "Truthful Examples:\n",
      "Accuracy: 28.0%\n",
      "Average Confidence: 0.479\n",
      "\n",
      "Hallucinated Examples:\n",
      "Accuracy: 76.0%\n",
      "Average Confidence: 0.489\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "## TRAINING DATASET EVALUATION\n",
    "\n",
    "# Assuming classifier is already initialized\n",
    "results_df = evaluate_model_predictions(classifier, truthful_examples_test, hallucinated_examples_test)\n",
    "\n",
    "# You can do additional analysis on results_df if needed\n",
    "# For example, look at high confidence mistakes:\n",
    "high_conf_mistakes = results_df[\n",
    "    (results_df['true_label'] != results_df['predicted']) & \n",
    "    (results_df['confidence'] > 0.8)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>true_label</th>\n",
       "      <th>predicted</th>\n",
       "      <th>confidence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [true_label, predicted, confidence]\n",
       "Index: []"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "high_conf_mistakes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Performance Interpretation\n",
    "\n",
    "The recall of 86% is quite good - the model catches 86% of all hallucinations. This aligns with your goal of preventing medical hallucinations, as it misses relatively few of them.\n",
    "The precision of 59.7% means that when the model flags something as a hallucination, it's right about 60% of the time. The relatively lower precision indicates that the model is somewhat aggressive in flagging content as hallucinated.\n",
    "This trade-off (high recall, moderate precision) might be acceptable for the medical use case, as:\n",
    "\n",
    "In medical contexts, missing a hallucination (false negative) could be more dangerous than incorrectly flagging truthful content (false positive)\n",
    "False positives can be manually reviewed, while missed hallucinations might go unnoticed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TEST DATASET EVALUATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
