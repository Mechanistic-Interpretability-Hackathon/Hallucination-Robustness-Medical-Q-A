{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import goodfire\n",
    "from typing import List, Dict, Tuple, Any\n",
    "import numpy as np\n",
    "\n",
    "class HallucinationClassifier:\n",
    "    def __init__(self, model_path: str, api_key: str):\n",
    "        \"\"\"\n",
    "        Initialize the hallucination classifier with a saved model and features.\n",
    "        \n",
    "        Args:\n",
    "            model_path: Path to the saved pickle file containing both the model and features\n",
    "            api_key: Goodfire API key for accessing the service\n",
    "        \"\"\"\n",
    "        # Load the model and features\n",
    "        with open(model_path, 'rb') as f:\n",
    "            model_data = pickle.load(f)\n",
    "            self.model = model_data['model']\n",
    "            self.features = model_data['features']\n",
    "        self.client = goodfire.Client(api_key)\n",
    "        self.variant = goodfire.Variant(\"meta-llama/Meta-Llama-3-8B-Instruct\")\n",
    "\n",
    "    def _format_prompt(self, question: str) -> List[Dict[str, str]]:\n",
    "        \"\"\"Format a question into the expected prompt structure.\"\"\"\n",
    "        introduction = (\"You are a medical expert and this is a multiple choice exam question. \"\n",
    "                      \"Please respond with the integer index of the CORRECT answer only; [0,1,2,3].\")\n",
    "        return [{\"role\": \"user\", \"content\": f\"{introduction}\\n\\n{question}\"}]\n",
    "\n",
    "    def _get_feature_activations(self, prompt: List[Dict[str, str]]) -> List[float]:\n",
    "        \"\"\"Get feature activations for the input prompt.\"\"\"\n",
    "        context = self.client.features.inspect(\n",
    "            prompt,\n",
    "            model=self.variant,\n",
    "            features=self.features\n",
    "        )\n",
    "        \n",
    "        # Get activations for our specific features\n",
    "        activations = []\n",
    "        features_dict = {f.uuid: 0.0 for f in self.features}\n",
    "        \n",
    "        for feature_act in context.top(k=len(self.features)):\n",
    "            if feature_act.feature.uuid in features_dict:\n",
    "                features_dict[feature_act.feature.uuid] = feature_act.activation\n",
    "        \n",
    "        # Maintain order matching the original features\n",
    "        for feature in self.features:\n",
    "            activations.append(features_dict[feature.uuid])\n",
    "            \n",
    "        return activations\n",
    "\n",
    "    def predict(self, question: str, debug: bool = False) -> Tuple[int, float]:\n",
    "        \"\"\"\n",
    "        Predict whether a given question-answer pair is likely to contain hallucination.\n",
    "        \n",
    "        Args:\n",
    "            question: The question text\n",
    "            debug: If True, print debugging information about feature activations\n",
    "            \n",
    "        Returns:\n",
    "            Tuple containing:\n",
    "            - Prediction (0 for truthful, 1 for hallucinated)\n",
    "            - Confidence score (probability of the predicted class)\n",
    "        \"\"\"\n",
    "        # Format the prompt\n",
    "        prompt = self._format_prompt(question)\n",
    "        \n",
    "        # Get feature activations\n",
    "        activations = self._get_feature_activations(prompt)\n",
    "        \n",
    "        if debug:\n",
    "            print(\"\\nFeature Activations:\")\n",
    "            for feature, activation in zip(self.features, activations):\n",
    "                print(f\"{feature.label}: {activation:.4f}\")\n",
    "            \n",
    "            # Get the decision path\n",
    "            decision_path = self.model.decision_path([activations])\n",
    "            feature_importance = self.model.feature_importances_\n",
    "            \n",
    "            print(\"\\nFeature Importance in Model:\")\n",
    "            for feature, importance in zip(self.features, feature_importance):\n",
    "                print(f\"{feature.label}: {importance:.4f}\")\n",
    "            \n",
    "            print(\"\\nDecision Path:\")\n",
    "            node_indicator = decision_path[0]\n",
    "            leaf_id = self.model.apply([activations])[0]\n",
    "            \n",
    "            # Get thresholds and feature indices for each node in path\n",
    "            for node_id in node_indicator.indices:\n",
    "                if node_id != leaf_id:\n",
    "                    feature_idx = self.model.tree_.feature[node_id]\n",
    "                    threshold = self.model.tree_.threshold[node_id]\n",
    "                    feature_name = self.features[feature_idx].label\n",
    "                    feature_value = activations[feature_idx]\n",
    "                    print(f\"Node {node_id}: {feature_name} = {feature_value:.4f} {'<=' if feature_value <= threshold else '>'} {threshold:.4f}\")\n",
    "        \n",
    "        # Make prediction\n",
    "        prediction = self.model.predict([activations])[0]\n",
    "        probabilities = self.model.predict_proba([activations])[0]\n",
    "        confidence = probabilities[prediction]\n",
    "        \n",
    "        if debug:\n",
    "            print(f\"\\nProbabilities:\")\n",
    "            print(f\"Truthful: {probabilities[0]:.4f}\")\n",
    "            print(f\"Hallucinated: {probabilities[1]:.4f}\")\n",
    "        \n",
    "        return int(prediction), float(confidence)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Feature Activations:\n",
      "The model should not recommend technological or medical interventions: 0.0000\n",
      "Specialized academic or scientific terminology: 0.6426\n",
      "Proper nouns in media and entertainment contexts: 0.0000\n",
      "\n",
      "Feature Importance in Model:\n",
      "The model should not recommend technological or medical interventions: 0.2505\n",
      "Specialized academic or scientific terminology: 0.5017\n",
      "Proper nouns in media and entertainment contexts: 0.2479\n",
      "\n",
      "Decision Path:\n",
      "Node 0: Specialized academic or scientific terminology = 0.6426 <= 0.7922\n",
      "Node 1: Proper nouns in media and entertainment contexts = 0.0000 <= 0.1416\n",
      "Node 2: The model should not recommend technological or medical interventions = 0.0000 <= 0.3314\n",
      "\n",
      "Probabilities:\n",
      "Truthful: 0.3816\n",
      "Hallucinated: 0.6184\n",
      "Prediction: Hallucinated\n",
      "Confidence: 0.62\n"
     ]
    }
   ],
   "source": [
    "# EXAMPLE USAGE\n",
    "\n",
    "model_path = \"../assets/hallucination_model.pkl\"\n",
    "api_key ='sk-goodfire-9IJgLomji2zNdvFLPsTYPQvPPr_kUC19bFTh0HgT9h6SikyfPB7WmQ'\n",
    "\n",
    "# Get the classifier model\n",
    "classifier = HallucinationClassifier(\n",
    "    model_path=model_path,\n",
    "    api_key=api_key\n",
    ")\n",
    "\n",
    "# Prepare example data\n",
    "prompt_example = \"\"\"You are a medical expert and this is a multiple choice exam question. Please respond with the integer index of the CORRECT answer only; [0,1,2,3].\n",
    "Mental disorders in the Diagnostic and Statistical Manual of the American Psychiatric Association, following a personality disorder that belongs to the species (cluster) with three other different?\n",
    "Options: {\"0\": \"Borderline\", \"1\": \"Antisocial\", \"2\": \"Paranoid\", \"3\": \"Drama type\"}\n",
    "\"\"\"\n",
    "\n",
    "# Get Prediction\n",
    "# Note usage of debug=True to demonstrate feature activations\n",
    "# In production you may want to use debug = False\n",
    "\n",
    "prediction, confidence = classifier.predict(prompt_example, debug=True)\n",
    "\n",
    "print(f\"Prediction: {'Hallucinated' if prediction == 1 else 'Truthful'}\")\n",
    "print(f\"Confidence: {confidence:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langgraph",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
